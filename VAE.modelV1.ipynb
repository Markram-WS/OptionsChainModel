{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/generative/vae/\n",
    "#https://keras.io/examples/generative/molecule_generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install --upgrade pip\n",
    "#!pip install pydot\n",
    "#!apt-get install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output,display, HTML\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "#================== initialization ==================\n",
    "currentTM=dt.datetime.now().strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "PROJECT = \"testVAEModel\"\n",
    "LATENT_DIM = 128\n",
    "VAE_LR = 5e-4\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "PARQUET_PATH = './data/OptionsEOD_STG.parquet'\n",
    "SCALER_PATH = './data/scaler.gz'\n",
    "UNIQUE_KEYS = ['QUOTE_DATE','SYMBOL','EXPIRE_DATE']\n",
    "SCALER_COL  = ['DTE','INTRINSIC_VALUE', 'TOTAL_VOLUME',\t'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK',\t'P_VOLUME' ]\n",
    "MODEL_PATH = \"./src/models/\"\n",
    "H5_PATH = './data/OptTrainData/'\n",
    "DISPLAY = False\n",
    "WANDB_LOG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/workspace/OptionsChainModel/wandb/run-20240630_051228-i6es3pad</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wasan-sinlapa/testVAEModel/runs/i6es3pad/workspace' target=\"_blank\">2024-06-30T051227</a></strong> to <a href='https://wandb.ai/wasan-sinlapa/testVAEModel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wasan-sinlapa/testVAEModel' target=\"_blank\">https://wandb.ai/wasan-sinlapa/testVAEModel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wasan-sinlapa/testVAEModel/runs/i6es3pad/workspace' target=\"_blank\">https://wandb.ai/wasan-sinlapa/testVAEModel/runs/i6es3pad/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#741d760b304d0be5b18d4ee9682f77156e6967b5\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()\n",
    "WANDB_LOG = True\n",
    "CONFIG = {    \"latent_dim\":LATENT_DIM,\n",
    "              \"learning_rate\": VAE_LR,\n",
    "              \"epochs\": EPOCHS,\n",
    "              \"batch_size\": BATCH_SIZE,\n",
    "              \"architecture\": \"VAE\",\n",
    "              \"dataset\": \"OptionsChaine\",\n",
    "              \"encoder_dense_units\":[512,256],\n",
    "              \"encoder_dropout_rate\":0.2,\n",
    "              \"decoder_dense_units\":[256, 512],\n",
    "              \"decoder_dropout_rate\":0.2,\n",
    "           }\n",
    "\n",
    "run = wandb.init(project=PROJECT, name=currentTM, config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "\n",
    "# from IPython.display import clear_output,display, HTML\n",
    "# import numpy as np\n",
    "# #load scaler\n",
    "# scaler = MinMaxScaler()\n",
    "# PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_PATH) if 'PartitionDate' in d]\n",
    "# random.shuffle(PartitionDate)\n",
    "# scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "\n",
    "# for i,partdate in enumerate(PartitionDate) :\n",
    "#     df = pd.read_parquet(PARQUET_PATH,engine='pyarrow'\n",
    "#                                  , filters=[('PartitionDate', '=', partdate)]\n",
    "#                                 )\n",
    "#     df['P_VOLUME'] = df['P_VOLUME'].fillna(0)\n",
    "#     df['C_VOLUME'] = df['C_VOLUME'].fillna(0)\n",
    "#     DATA  = np.empty((0,) + (20,9) ) \n",
    "#     for opt_id in np.unique( df[[\"OPTIONS_ID\"]].values):\n",
    "#         df_filter  = df[df[\"OPTIONS_ID\"]==opt_id]\n",
    "#         if len(df_filter) == 20:\n",
    "#             DATA = np.vstack((DATA ,[scaler.transform(df_filter[SCALER_COL])]))\n",
    "#         else:\n",
    "#             #print( len(df_filter) )\n",
    "#             #display(HTML(df_filter[['STRIKE']+SCALER_COL].to_html()))\n",
    "#             pass\n",
    "            \n",
    "#     ## Save the NumPy array to an HDF5 file\n",
    "#     # with h5py.File(H5_PATH+f\"{partdate}.h5\", 'w') as f:\n",
    "#     #     dset = f.create_dataset(f'{partdate}', data=DATA, chunks=True , compression='gzip')\n",
    "\n",
    "#     print(f\"[Processing] {partdate}, {round(((i+1)/len(PartitionDate))*100,2)}%     \",end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the NumPy array to an HDF5 file\n",
    "# with h5py.File(H5_PATH, 'w') as f:\n",
    "#     #dset = f.create_dataset('dataset', data=DATA, chunks=True, compression='gzip')\n",
    "#     #test\n",
    "#     dset = f.create_dataset('dataset', data=DATA, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import OptionChainGenerator\n",
    "from src.layer import encoder, decoder\n",
    "\n",
    "model = OptionChainGenerator(\n",
    "    encoder(latent_dim = LATENT_DIM, \n",
    "            input_shape= (20,3), \n",
    "            dense_units = CONFIG[\"encoder_dense_units\"], \n",
    "            dropout_rate= CONFIG[\"encoder_dropout_rate\"]\n",
    "           ), \n",
    "    decoder(latent_dim  = LATENT_DIM , \n",
    "            output_shape= (20,1),\n",
    "            dense_units = CONFIG[\"decoder_dense_units\"],\n",
    "            dropout_rate= CONFIG[\"decoder_dropout_rate\"]\n",
    "           )\n",
    ")\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return 0.0\n",
    "    \n",
    "vae_optimizer = tf.keras.optimizers.Adam(learning_rate=VAE_LR)\n",
    "model.compile(vae_optimizer , loss=dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## show model ######################\n",
    "if DISPLAY :\n",
    "    from tensorflow.keras.utils import model_to_dot\n",
    "    from IPython.display import SVG, display\n",
    "    \n",
    "    def display_model(model, width=1024, height=512):\n",
    "        dot = model_to_dot(model, show_shapes=True, show_layer_names=True)\n",
    "        svg_data = dot.create(prog='dot', format='svg').decode(\"utf-8\")\n",
    "        svg_html = f'<div style=\"width:{width}px;height:{height}px;\">{svg_data}</div>'\n",
    "        display(HTML(svg_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage:\n",
    "## Display the encoder model with reduced size\n",
    "if DISPLAY :\n",
    "    display_model(model.encoder, width=1024, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY :\n",
    "    display_model(model.decoder, width=2500, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== loadmodel ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_path = MODEL_PATH+f'{PROJECT}'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    model.encoder.save(model_path+f'/'+f'encoder.keras') \n",
    "    model.decoder.save(model_path+f'/'+f'decoder.keras') \n",
    "else:\n",
    "    model.encoder = load_model(model_path+'/'+f'encoder.keras') \n",
    "    model.decoder = load_model(model_path+'/'+f'decoder.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:576: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - kl_loss: 6.3055e-04 - optVal_loss: 0.6118 - total_loss: 0.6181 - vol_loss: 0.0056 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: 1.1648e-04 - optVal_loss: 0.5553 - total_loss: 0.5563 - vol_loss: 8.8743e-04 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 7.8789e-05 - optVal_loss: 0.5126 - total_loss: 0.5131 - vol_loss: 4.3880e-04 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 7.1050e-05 - optVal_loss: 0.5572 - total_loss: 0.5576 - vol_loss: 3.7405e-04 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 1.2160e-04 - optVal_loss: 0.4805 - total_loss: 0.4807 - vol_loss: 1.1304e-04 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - kl_loss: 4.5848e-05 - optVal_loss: 0.7482 - total_loss: 0.7501 - vol_loss: 0.0019 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 4.0105e-05 - optVal_loss: 0.8639 - total_loss: 0.8666 - vol_loss: 0.0027 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 5.6092e-05 - optVal_loss: 0.7986 - total_loss: 0.8010 - vol_loss: 0.0024 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 4.1217e-05 - optVal_loss: 0.7159 - total_loss: 0.7184 - vol_loss: 0.0025 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 3.2932e-05 - optVal_loss: 0.8370 - total_loss: 0.8396 - vol_loss: 0.0026 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: 3.5111e-05 - optVal_loss: 0.7190 - total_loss: 0.7201 - vol_loss: 0.0011 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: 3.6735e-05 - optVal_loss: 0.5892 - total_loss: 0.5903 - vol_loss: 0.0011 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: 4.9396e-05 - optVal_loss: 0.5859 - total_loss: 0.5879 - vol_loss: 0.0019 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 3.3946e-05 - optVal_loss: 0.6561 - total_loss: 0.6574 - vol_loss: 0.0012 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 2.4189e-05 - optVal_loss: 0.5954 - total_loss: 0.5966 - vol_loss: 0.0012 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - kl_loss: 2.8355e-05 - optVal_loss: 0.7942 - total_loss: 0.7983 - vol_loss: 0.0040 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 2.0893e-05 - optVal_loss: 0.7226 - total_loss: 0.7258 - vol_loss: 0.0032 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 1.7869e-05 - optVal_loss: 0.7852 - total_loss: 0.7885 - vol_loss: 0.0034 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 1.3514e-05 - optVal_loss: 0.7491 - total_loss: 0.7524 - vol_loss: 0.0033 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 1.1192e-05 - optVal_loss: 0.7424 - total_loss: 0.7458 - vol_loss: 0.0034 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - kl_loss: 2.5839e-05 - optVal_loss: 0.2020 - total_loss: 0.2020 - vol_loss: 0.0000e+00 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - kl_loss: 2.8372e-05 - optVal_loss: 0.2255 - total_loss: 0.2255 - vol_loss: 0.0000e+00 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - kl_loss: 3.4571e-05 - optVal_loss: 0.1985 - total_loss: 0.1986 - vol_loss: 0.0000e+00 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - kl_loss: 4.5866e-05 - optVal_loss: 0.1502 - total_loss: 0.1503 - vol_loss: 1.0553e-04 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - kl_loss: 6.1333e-05 - optVal_loss: 0.1398 - total_loss: 0.1399 - vol_loss: 3.1329e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: 1.3407e-04 - optVal_loss: 1.5336 - total_loss: 1.5338 - vol_loss: 7.7822e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 5.9442e-05 - optVal_loss: 1.1911 - total_loss: 1.1912 - vol_loss: 3.2399e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 8.4359e-05 - optVal_loss: 1.1816 - total_loss: 1.1817 - vol_loss: 1.8331e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 1.1628e-04 - optVal_loss: 1.0733 - total_loss: 1.0735 - vol_loss: 2.6533e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 1.8026e-04 - optVal_loss: 1.2645 - total_loss: 1.2647 - vol_loss: 1.5849e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: 1.5962e-04 - optVal_loss: 1.1456 - total_loss: 1.1458 - vol_loss: 5.4120e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 3.7446e-05 - optVal_loss: 1.0906 - total_loss: 1.0907 - vol_loss: 5.1166e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 1.4730e-05 - optVal_loss: 0.9678 - total_loss: 0.9679 - vol_loss: 3.7303e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 1.1015e-05 - optVal_loss: 1.0061 - total_loss: 1.0062 - vol_loss: 6.6224e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 1.0536e-05 - optVal_loss: 1.0019 - total_loss: 1.0020 - vol_loss: 7.0653e-05 - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -24018us/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -8990us/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 1/5\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan - loss: 0.0000e+00 - val_kl_loss: 0.0000e+00 - val_loss: 0.0000e+00 - val_optVal_loss: 0.0000e+00 - val_total_loss: 0.0000e+00 - val_vol_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - optVal_loss: nan - total_loss: nan - vol_loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         random\u001b[38;5;241m.\u001b[39mshuffle(PartitionDate)\n\u001b[1;32m     11\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session() \n\u001b[0;32m---> 12\u001b[0m         history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m WANDB_LOG :\n\u001b[1;32m     14\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39maverage(  history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m     16\u001b[0m         ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m:np\u001b[38;5;241m.\u001b[39maverage(  history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m     17\u001b[0m         ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptVal_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:np\u001b[38;5;241m.\u001b[39maverage(  history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptVal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m     18\u001b[0m         ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvol_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:np\u001b[38;5;241m.\u001b[39maverage(  history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m     19\u001b[0m     }, commit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#================== train model ==================\n",
    "PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_PATH) if 'PartitionDate' in d]\n",
    "random.shuffle(PartitionDate)\n",
    "for partdate in PartitionDate[:]:\n",
    "    with h5py.File(H5_PATH+partdate+\".h5\", 'r') as f:\n",
    "        DATA = f[partdate][:]\n",
    "        X = DATA[:, :, :3]  # เลือกข้อมูลแถวแรกถึงแถวที่ 3 สำหรับ X\n",
    "        Y = DATA[:, :, 3:]  # เลือกข้อมูลแถวที่ 3 เป็นต้นไปสำหรับ Y\n",
    "        if len(X) :\n",
    "            random.shuffle(PartitionDate)\n",
    "            tf.keras.backend.clear_session() \n",
    "            history = model.fit(X , Y, epochs=5, batch_size=BATCH_SIZE, validation_split=0.2)\n",
    "    if WANDB_LOG :\n",
    "        wandb.log({\n",
    "            \"kl_loss\": np.average(  history.history['kl_loss'] )\n",
    "            ,\"loss\":np.average(  history.history['loss'] )\n",
    "            ,\"optVal_loss\":np.average(  history.history['optVal_loss'] )\n",
    "            ,\"vol_loss\":np.average(  history.history['vol_loss'] )\n",
    "        }, commit=True)\n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "    model.encoder.save(model_path+f'/'+f'encoder.keras') \n",
    "    model.decoder.save(model_path+f'/'+f'decoder.keras') \n",
    "if WANDB_LOG : wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['kl_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(  history.history['kl_loss'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(H5_PATH+'2012-05'+\".h5\", 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_adjacency_matrix(options, threshold=25):\n",
    "    \"\"\"\n",
    "    สร้าง adjacency matrix สำหรับ Options Chain โดยใช้ความใกล้เคียงของ strike price และ DTE\n",
    "    \"\"\"\n",
    "    num_options = len(options)\n",
    "    adjacency_matrix = np.zeros((num_options, num_options))\n",
    "\n",
    "    for i in range(num_options):\n",
    "        for j in range(i, num_options):\n",
    "            # พิจารณาเชื่อมโยงระหว่าง options หาก strike price ต่างกันไม่เกิน threshold และ DTE เท่ากัน\n",
    "            if abs(options[i]['strike_price'] - options[j]['strike_price']) <= threshold and options[i]['dte'] == options[j]['dte']:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "options = [\n",
    "    {'strike_price': 100, 'dte': 30},\n",
    "    {'strike_price': 105, 'dte': 30},\n",
    "    {'strike_price': 110, 'dte': 30},\n",
    "    {'strike_price': 115, 'dte': 30},\n",
    "    {'strike_price': 120, 'dte': 30},\n",
    "    {'strike_price': 0, 'dte': 0},  # เปลี่ยนค่าเป็น 0\n",
    "]\n",
    "\n",
    "options = [\n",
    "    {'strike_price': 0, 'dte': 0},\n",
    "    {'strike_price': 120, 'dte': 30},\n",
    "    {'strike_price': 150, 'dte': 30},\n",
    "    {'strike_price': 110, 'dte': 30},\n",
    "    {'strike_price': 105, 'dte': 30},\n",
    "    {'strike_price': 100, 'dte': 30},  # เปลี่ยนค่าเป็น 0\n",
    "]\n",
    "\n",
    "\n",
    "# ปรับ threshold\n",
    "threshold = 5\n",
    "\n",
    "adjacency_matrix = create_adjacency_matrix(options, threshold)\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array(\n",
    "    [[1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a random numpy array with shape (2, 20, 6)\n",
    "random_array = np.random.rand(2, 20, 6)\n",
    "\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.random.rand(2, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array[:, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = [\"c_bid\", \"c_ask\", \"c_volume\", \"p_bid\", \"p_ask\", \"p_volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList.index(\"c_ask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f77a7efb8cf15d18a0cd6bbc71a8985efbc57e2467f435a53ada42728ce0a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
