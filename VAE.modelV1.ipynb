{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/generative/vae/\n",
    "#https://keras.io/examples/generative/molecule_generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install --upgrade pip\n",
    "#!pip install pydot\n",
    "#!apt-get install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:09:37.027443: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os,shutil,random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output,display, HTML\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "#================== initialization ==================\n",
    "currentTM=dt.datetime.now().strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "PROJECT = \"testVAEModel\"\n",
    "LATENT_DIM = 128\n",
    "VAE_LR = 1e-4\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "PARQUET_PATH = './data/OptionsEOD_STG.parquet'\n",
    "SCALER_PATH = './data/scaler.gz'\n",
    "UNIQUE_KEYS = ['QUOTE_DATE','SYMBOL','EXPIRE_DATE']\n",
    "SCALER_COL  = ['DTE','INTRINSIC_VALUE', 'TOTAL_VOLUME',\t'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK',\t'P_VOLUME' ]\n",
    "MODEL_PATH = \"./models/\"\n",
    "H5_PATH = './data/OptTrainData/'\n",
    "DISPLAY = False\n",
    "WANDB_LOG = False\n",
    "RESUME = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwasan-sinlapa\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/workspace/OptionsChainModel/wandb/run-20240702_150940-rc32yvq0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wasan-sinlapa/testVAEModel/runs/rc32yvq0/workspace' target=\"_blank\">2024-07-02T150938</a></strong> to <a href='https://wandb.ai/wasan-sinlapa/testVAEModel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wasan-sinlapa/testVAEModel' target=\"_blank\">https://wandb.ai/wasan-sinlapa/testVAEModel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wasan-sinlapa/testVAEModel/runs/rc32yvq0/workspace' target=\"_blank\">https://wandb.ai/wasan-sinlapa/testVAEModel/runs/rc32yvq0/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#741d760b304d0be5b18d4ee9682f77156e6967b5\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()\n",
    "WANDB_LOG = True\n",
    "CONFIG = {    \"latent_dim\":LATENT_DIM,\n",
    "              \"learning_rate\": VAE_LR,\n",
    "              \"epochs\": EPOCHS,\n",
    "              \"batch_size\": BATCH_SIZE,\n",
    "              \"architecture\": \"VAE\",\n",
    "              \"dataset\": \"OptionsChaine\",\n",
    "              \"encoder_dense_units\":[512,256],\n",
    "              \"encoder_dropout_rate\":0.2,\n",
    "              \"decoder_dense_units\":[256, 512],\n",
    "              \"decoder_dropout_rate\":0.2,\n",
    "           }\n",
    "\n",
    "run = wandb.init(project=PROJECT, name=currentTM, config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "\n",
    "# from IPython.display import clear_output,display, HTML\n",
    "# import numpy as np\n",
    "# #load scaler\n",
    "# scaler = MinMaxScaler()\n",
    "# PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_PATH) if 'PartitionDate' in d]\n",
    "# random.shuffle(PartitionDate)\n",
    "# scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "\n",
    "# for i,partdate in enumerate(PartitionDate) :\n",
    "#     df = pd.read_parquet(PARQUET_PATH,engine='pyarrow'\n",
    "#                                  , filters=[('PartitionDate', '=', partdate)]\n",
    "#                                 )\n",
    "#     df['P_VOLUME'] = df['P_VOLUME'].fillna(0)\n",
    "#     df['C_VOLUME'] = df['C_VOLUME'].fillna(0)\n",
    "#     DATA  = np.empty((0,) + (20,9) ) \n",
    "#     for opt_id in np.unique( df[[\"OPTIONS_ID\"]].values):\n",
    "#         df_filter  = df[df[\"OPTIONS_ID\"]==opt_id]\n",
    "#         if len(df_filter) == 20:\n",
    "#             DATA = np.vstack((DATA ,[scaler.transform(df_filter[SCALER_COL])]))\n",
    "#         else:\n",
    "#             #print( len(df_filter) )\n",
    "#             #display(HTML(df_filter[['STRIKE']+SCALER_COL].to_html()))\n",
    "#             pass\n",
    "            \n",
    "#     ## Save the NumPy array to an HDF5 file\n",
    "#     # with h5py.File(H5_PATH+f\"{partdate}.h5\", 'w') as f:\n",
    "#     #     dset = f.create_dataset(f'{partdate}', data=DATA, chunks=True , compression='gzip')\n",
    "\n",
    "#     print(f\"[Processing] {partdate}, {round(((i+1)/len(PartitionDate))*100,2)}%     \",end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the NumPy array to an HDF5 file\n",
    "# with h5py.File(H5_PATH, 'w') as f:\n",
    "#     #dset = f.create_dataset('dataset', data=DATA, chunks=True, compression='gzip')\n",
    "#     #test\n",
    "#     dset = f.create_dataset('dataset', data=DATA, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import OptionChainGenerator\n",
    "from src.layer import encoder, decoder\n",
    "\n",
    "model = OptionChainGenerator(\n",
    "    encoder(latent_dim = LATENT_DIM, \n",
    "            input_shape= (20,3), \n",
    "            dense_units = CONFIG[\"encoder_dense_units\"], \n",
    "            dropout_rate= CONFIG[\"encoder_dropout_rate\"]\n",
    "           ), \n",
    "    decoder(latent_dim  = LATENT_DIM , \n",
    "            output_shape= (20,1),\n",
    "            dense_units = CONFIG[\"decoder_dense_units\"],\n",
    "            dropout_rate= CONFIG[\"decoder_dropout_rate\"]\n",
    "           )\n",
    ")\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return 0.0\n",
    "    \n",
    "vae_optimizer = tf.keras.optimizers.Adam(learning_rate=VAE_LR)\n",
    "model.compile(vae_optimizer )#, loss=dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## show model ######################\n",
    "if DISPLAY :\n",
    "    from tensorflow.keras.utils import model_to_dot\n",
    "    from IPython.display import SVG, display\n",
    "    \n",
    "    def display_model(model, width=1024, height=512):\n",
    "        dot = model_to_dot(model, show_shapes=True, show_layer_names=True)\n",
    "        svg_data = dot.create(prog='dot', format='svg').decode(\"utf-8\")\n",
    "        svg_html = f'<div style=\"width:{width}px;height:{height}px;\">{svg_data}</div>'\n",
    "        display(HTML(svg_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage:\n",
    "## Display the encoder model with reduced size\n",
    "if DISPLAY :\n",
    "    display_model(model.encoder, width=1024, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY :\n",
    "    display_model(model.decoder, width=2500, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== loadmodel ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_path = MODEL_PATH+f'{PROJECT}'\n",
    "if not RESUME :\n",
    "    if os.path.exists(model_path) :\n",
    "        shutil.rmtree(model_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    model.encoder.save(model_path+f'/'+f'encoder.keras') \n",
    "    model.decoder.save(model_path+f'/'+f'decoder.keras') \n",
    "else:\n",
    "    model.encoder = load_model(model_path+'/'+f'encoder.keras') \n",
    "    model.decoder = load_model(model_path+'/'+f'decoder.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:576: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - kl_loss: 0.0532 - total_loss: 38.8123 - vol_loss: 53.3721 - val_kl_loss: 0.0670 - val_total_loss: 1.0033 - val_vol_loss: 38.0366\n",
      "Epoch 2/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 0.0860 - total_loss: 2.4861 - vol_loss: 55.3245 - val_kl_loss: 0.0606 - val_total_loss: 0.7016 - val_vol_loss: 40.7359\n",
      "Epoch 3/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0725 - total_loss: 1.3377 - vol_loss: 58.0737 - val_kl_loss: 0.0420 - val_total_loss: 0.6801 - val_vol_loss: 42.8944\n",
      "Epoch 4/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0525 - total_loss: 1.0773 - vol_loss: 57.0123 - val_kl_loss: 0.0274 - val_total_loss: 0.6625 - val_vol_loss: 41.9100\n",
      "Epoch 5/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0371 - total_loss: 0.9718 - vol_loss: 59.4279 - val_kl_loss: 0.0179 - val_total_loss: 0.6586 - val_vol_loss: 42.3265\n",
      "Epoch 1/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - kl_loss: 0.0280 - total_loss: 4.7111 - vol_loss: 59.9888 - val_kl_loss: 0.0108 - val_total_loss: 4.7841 - val_vol_loss: 43.0888\n",
      "Epoch 2/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 0.0181 - total_loss: 4.2870 - vol_loss: 59.0444 - val_kl_loss: 0.0064 - val_total_loss: 4.5610 - val_vol_loss: 41.6438\n",
      "Epoch 3/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0127 - total_loss: 3.6087 - vol_loss: 58.0366 - val_kl_loss: 0.0042 - val_total_loss: 4.3954 - val_vol_loss: 42.5442\n",
      "Epoch 4/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0098 - total_loss: 3.8766 - vol_loss: 57.0064 - val_kl_loss: 0.0030 - val_total_loss: 4.3015 - val_vol_loss: 39.2363\n",
      "Epoch 5/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0079 - total_loss: 4.1861 - vol_loss: 55.9006 - val_kl_loss: 0.0022 - val_total_loss: 4.3241 - val_vol_loss: 41.1150\n",
      "Epoch 1/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - kl_loss: 0.0061 - total_loss: 1.5002 - vol_loss: 56.3320 - val_kl_loss: 0.0018 - val_total_loss: 1.4468 - val_vol_loss: 42.0879\n",
      "Epoch 2/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 0.0055 - total_loss: 1.2550 - vol_loss: 58.9214 - val_kl_loss: 0.0015 - val_total_loss: 1.4850 - val_vol_loss: 42.0196\n",
      "Epoch 3/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 0.0048 - total_loss: 1.2020 - vol_loss: 56.9707 - val_kl_loss: 0.0012 - val_total_loss: 1.5114 - val_vol_loss: 43.1188\n",
      "Epoch 4/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0042 - total_loss: 1.2381 - vol_loss: 56.9335 - val_kl_loss: 9.7763e-04 - val_total_loss: 1.5087 - val_vol_loss: 41.3401\n",
      "Epoch 5/5\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0036 - total_loss: 1.0983 - vol_loss: 57.8246 - val_kl_loss: 7.9798e-04 - val_total_loss: 1.5045 - val_vol_loss: 40.3398\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: 0.0030 - total_loss: 0.5464 - vol_loss: 56.0194 - val_kl_loss: 7.0962e-04 - val_total_loss: 0.2964 - val_vol_loss: 42.4528\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: 0.0029 - total_loss: 0.5341 - vol_loss: 57.0571 - val_kl_loss: 6.7075e-04 - val_total_loss: 0.2917 - val_vol_loss: 43.2461\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 0.0026 - total_loss: 0.4992 - vol_loss: 60.1737 - val_kl_loss: 6.2677e-04 - val_total_loss: 0.2932 - val_vol_loss: 43.5861\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 0.0024 - total_loss: 0.4626 - vol_loss: 60.3018 - val_kl_loss: 5.9988e-04 - val_total_loss: 0.2919 - val_vol_loss: 43.2660\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 0.0023 - total_loss: 0.5113 - vol_loss: 61.5160 - val_kl_loss: 5.5974e-04 - val_total_loss: 0.2903 - val_vol_loss: 43.2228\n",
      "Epoch 1/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - kl_loss: 0.0022 - total_loss: 1.8125 - vol_loss: 60.2751 - val_kl_loss: 4.8310e-04 - val_total_loss: 2.5216 - val_vol_loss: 44.2898\n",
      "Epoch 2/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 0.0019 - total_loss: 1.7284 - vol_loss: 59.5403 - val_kl_loss: 4.0828e-04 - val_total_loss: 2.4063 - val_vol_loss: 42.3348\n",
      "Epoch 3/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0016 - total_loss: 1.7181 - vol_loss: 59.5903 - val_kl_loss: 3.7085e-04 - val_total_loss: 2.2412 - val_vol_loss: 41.7694\n",
      "Epoch 4/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0014 - total_loss: 1.6618 - vol_loss: 58.1258 - val_kl_loss: 3.6121e-04 - val_total_loss: 2.2021 - val_vol_loss: 40.3901\n",
      "Epoch 5/5\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 0.0012 - total_loss: 1.5526 - vol_loss: 56.9438 - val_kl_loss: 3.4778e-04 - val_total_loss: 2.2035 - val_vol_loss: 40.3975\n",
      "Epoch 1/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - kl_loss: 0.0011 - total_loss: 0.7247 - vol_loss: 51.9634 - val_kl_loss: 3.4746e-04 - val_total_loss: 0.6602 - val_vol_loss: 40.7325\n",
      "Epoch 2/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 0.0011 - total_loss: 0.6761 - vol_loss: 52.5610 - val_kl_loss: 3.4665e-04 - val_total_loss: 0.7398 - val_vol_loss: 42.4261\n",
      "Epoch 3/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 0.0010 - total_loss: 0.6449 - vol_loss: 55.4751 - val_kl_loss: 3.4390e-04 - val_total_loss: 0.7807 - val_vol_loss: 40.5287\n",
      "Epoch 4/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 0.0010 - total_loss: 0.6125 - vol_loss: 53.0982 - val_kl_loss: 3.4014e-04 - val_total_loss: 0.7901 - val_vol_loss: 39.8908\n",
      "Epoch 5/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 9.9911e-04 - total_loss: 0.5912 - vol_loss: 52.5380 - val_kl_loss: 3.3690e-04 - val_total_loss: 0.7850 - val_vol_loss: 42.2382\n",
      "Epoch 1/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - kl_loss: 9.1061e-04 - total_loss: 0.7775 - vol_loss: 54.5418 - val_kl_loss: 3.2329e-04 - val_total_loss: 0.9390 - val_vol_loss: 39.3935\n",
      "Epoch 2/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: 8.8023e-04 - total_loss: 0.8046 - vol_loss: 53.8315 - val_kl_loss: 3.1881e-04 - val_total_loss: 0.9334 - val_vol_loss: 40.8943\n",
      "Epoch 3/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 8.7221e-04 - total_loss: 0.7922 - vol_loss: 55.7880 - val_kl_loss: 3.1527e-04 - val_total_loss: 0.9354 - val_vol_loss: 42.8059\n",
      "Epoch 4/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 7.8271e-04 - total_loss: 0.7559 - vol_loss: 55.1049 - val_kl_loss: 3.1135e-04 - val_total_loss: 0.9391 - val_vol_loss: 44.4884\n",
      "Epoch 5/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 7.7760e-04 - total_loss: 0.7564 - vol_loss: 54.0639 - val_kl_loss: 3.0561e-04 - val_total_loss: 0.9248 - val_vol_loss: 41.8970\n",
      "Epoch 1/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - kl_loss: 8.0540e-04 - total_loss: 0.4915 - vol_loss: 57.1711 - val_kl_loss: 3.0034e-04 - val_total_loss: 0.5724 - val_vol_loss: 40.9037\n",
      "Epoch 2/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - kl_loss: 7.6044e-04 - total_loss: 0.4704 - vol_loss: 57.6990 - val_kl_loss: 2.8656e-04 - val_total_loss: 0.5842 - val_vol_loss: 43.2249\n",
      "Epoch 3/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 7.2701e-04 - total_loss: 0.4888 - vol_loss: 58.0647 - val_kl_loss: 2.7130e-04 - val_total_loss: 0.5852 - val_vol_loss: 40.0210\n",
      "Epoch 4/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 6.8549e-04 - total_loss: 0.5157 - vol_loss: 58.0878 - val_kl_loss: 2.5722e-04 - val_total_loss: 0.5881 - val_vol_loss: 40.6359\n",
      "Epoch 5/5\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 6.2659e-04 - total_loss: 0.4411 - vol_loss: 59.4311 - val_kl_loss: 2.4272e-04 - val_total_loss: 0.5871 - val_vol_loss: 44.8482\n",
      "Epoch 1/5\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: 5.8525e-04 - total_loss: 0.7189 - vol_loss: 56.9648 - val_kl_loss: 2.2700e-04 - val_total_loss: 0.7101 - val_vol_loss: 42.6583\n",
      "Epoch 2/5\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 5.4872e-04 - total_loss: 0.7624 - vol_loss: 58.7374 - val_kl_loss: 2.1184e-04 - val_total_loss: 0.7132 - val_vol_loss: 42.3622\n",
      "Epoch 3/5\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 5.1273e-04 - total_loss: 0.7854 - vol_loss: 59.4081 - val_kl_loss: 1.9867e-04 - val_total_loss: 0.7120 - val_vol_loss: 41.6921\n",
      "Epoch 4/5\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: 4.8935e-04 - total_loss: 0.8312 - vol_loss: 59.5793 - val_kl_loss: 1.8616e-04 - val_total_loss: 0.7051 - val_vol_loss: 41.2588\n",
      "Epoch 5/5\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: 4.5293e-04 - total_loss: 0.6402 - vol_loss: 56.3398 - val_kl_loss: 1.7544e-04 - val_total_loss: 0.7093 - val_vol_loss: 43.2242\n",
      "Epoch 1/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - kl_loss: 4.0993e-04 - total_loss: 0.6661 - vol_loss: 54.4896 - val_kl_loss: 1.7076e-04 - val_total_loss: 0.8592 - val_vol_loss: 41.2085\n",
      "Epoch 2/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 3.9287e-04 - total_loss: 0.7264 - vol_loss: 54.8800 - val_kl_loss: 1.6576e-04 - val_total_loss: 0.8626 - val_vol_loss: 42.3136\n",
      "Epoch 3/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 4.0634e-04 - total_loss: 0.6672 - vol_loss: 52.6456 - val_kl_loss: 1.6084e-04 - val_total_loss: 0.8391 - val_vol_loss: 39.5247\n",
      "Epoch 4/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 4.2506e-04 - total_loss: 0.6850 - vol_loss: 55.6950 - val_kl_loss: 1.5660e-04 - val_total_loss: 0.8518 - val_vol_loss: 41.2915\n",
      "Epoch 5/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: 3.5344e-04 - total_loss: 0.6365 - vol_loss: 54.8433 - val_kl_loss: 1.5289e-04 - val_total_loss: 0.8291 - val_vol_loss: 41.4401\n",
      "Epoch 1/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 1/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 2/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 3/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 4/5\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan - val_kl_loss: nan - val_total_loss: nan - val_vol_loss: nan\n",
      "Epoch 5/5\n",
      "\u001b[1m 8/27\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: nan - total_loss: nan - vol_loss: nan "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#================== train model ==================\n",
    "PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_PATH) if 'PartitionDate' in d]\n",
    "random.shuffle(PartitionDate)\n",
    "\n",
    "STOP_MODEL = False\n",
    "for partdate in PartitionDate[:] :\n",
    "    #nan problem\n",
    "    #partdate = '2022-05'\n",
    "    #normal \n",
    "    #partdate = '2011-12'\n",
    "    \n",
    "    with h5py.File(H5_PATH+partdate+\".h5\", 'r') as f:\n",
    "        DATA = f[partdate][:]\n",
    "        X = DATA[:, :, :3]  # เลือกข้อมูลแถวแรกถึงแถวที่ 3 สำหรับ X\n",
    "        Y = DATA[:, :, 3:]  # เลือกข้อมูลแถวที่ 3 เป็นต้นไปสำหรับ Y\n",
    "        if len(X) :\n",
    "            random.shuffle(PartitionDate)\n",
    "            tf.keras.backend.clear_session() \n",
    "            history = model.fit(X , Y, epochs=5, batch_size=BATCH_SIZE, validation_split=0.2)\n",
    "\n",
    "            if  np.isnan(  np.average( history.history['kl_loss'] )  ):\n",
    "                STOP_MODEL = True \n",
    "            \n",
    "    if WANDB_LOG :\n",
    "        wandb.log({\n",
    "            \"kl_loss\": np.average(  history.history['kl_loss'] )\n",
    "            ,\"total_loss\":np.average(  history.history['total_loss'] )\n",
    "            ,\"vol_loss\":np.average(  history.history['vol_loss'] )\n",
    "\n",
    "            ,'val_kl_loss':np.average(  history.history['val_kl_loss'] )\n",
    "            ,'val_total_loss':np.average(  history.history['val_total_loss'] )\n",
    "            , 'val_vol_loss':np.average(  history.history['val_vol_loss'] )\n",
    "        }, commit=True)\n",
    "        \n",
    "        # wandb.log({\n",
    "        #     \"kl_loss\": np.average(  history.history['kl_loss'] )\n",
    "        #     ,\"total_loss\":np.average(  history.history['total_loss'] )\n",
    "        #     ,\"loss\":np.average(  history.history['loss'] )\n",
    "        #     ,\"optVal_loss\":np.average(  history.history['optVal_loss'] )\n",
    "        #     ,\"vol_loss\":np.average(  history.history['vol_loss'] )\n",
    "        # }, commit=True)\n",
    "\n",
    "    if STOP_MODEL :\n",
    "        break\n",
    "    \n",
    "            \n",
    "    model.encoder.save(model_path+f'/'+f'encoder.keras') \n",
    "    model.decoder.save(model_path+f'/'+f'decoder.keras') \n",
    "if WANDB_LOG : wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kl_loss', 'total_loss', 'vol_loss', 'val_kl_loss', 'val_total_loss', 'val_vol_loss'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nan problem\n",
    "#partdate = '2022-05'\n",
    "#normal \n",
    "#partdate = '2011-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partdate = '2011-12'\n",
    "# partdate = '2022-05'\n",
    "# with h5py.File(H5_PATH+partdate+\".h5\", 'r') as f:\n",
    "#     DATA = f[partdate][:]\n",
    "#     X = DATA[:, :, :3]  # เลือกข้อมูลแถวแรกถึงแถวที่ 3 สำหรับ X\n",
    "#     Y = DATA[:, :, 3:]  # เลือกข้อมูลแถวที่ 3 เป็นต้นไปสำหรับ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range ( len( np.transpose( Y[0] ) ) ):\n",
    "    col = np.transpose( Y[i] ) \n",
    "    for c in range(len(col)):\n",
    "        a = np.transpose( Y[i] )[c]\n",
    "        if np.sum( a ) == 0 :\n",
    "            print(f\"0 - i:{i},c:{c}\")\n",
    "        if np.isnan( np.sum( a ) ) :\n",
    "            print(f\"nan - i:{i},c:{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range ( len( np.transpose( X[0] ) ) ):\n",
    "    col = np.transpose( X[i] ) \n",
    "    for c in range(len(col)):\n",
    "        a = np.transpose( X[i] )[c]\n",
    "        if np.sum( a ) == 0 :\n",
    "            print(f\"0 - i:{i},c:{c}\")\n",
    "        if np.isnan( np.sum( a ) ) :\n",
    "            print(f\"nan - i:{i},c:{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose( X[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose( Y[2] )[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose( Y[2] )[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[2][8:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Tensor with a nan value\n",
    "tensor_with_nan = tf.constant([[0.0, 0, 0], [0, 0, 0]])\n",
    "# Perform reduce_mean\n",
    "mean_with_nan = tf.reduce_mean(tensor_with_nan)\n",
    "print(\"Mean of tensor with nan:\", mean_with_nan.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_with_nan.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[2][-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range( len(X) ): \n",
    "    if np.sum( X[i] ) == 0 :\n",
    "        print(   np.sum( X[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range( len(Y) ): \n",
    "    if np.sum( Y[i] ) == 0 :\n",
    "        print(   np.sum( Y[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(  history.history['kl_loss'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(H5_PATH+'2012-05'+\".h5\", 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_adjacency_matrix(options, threshold=25):\n",
    "    \"\"\"\n",
    "    สร้าง adjacency matrix สำหรับ Options Chain โดยใช้ความใกล้เคียงของ strike price และ DTE\n",
    "    \"\"\"\n",
    "    num_options = len(options)\n",
    "    adjacency_matrix = np.zeros((num_options, num_options))\n",
    "\n",
    "    for i in range(num_options):\n",
    "        for j in range(i, num_options):\n",
    "            # พิจารณาเชื่อมโยงระหว่าง options หาก strike price ต่างกันไม่เกิน threshold และ DTE เท่ากัน\n",
    "            if abs(options[i]['strike_price'] - options[j]['strike_price']) <= threshold and options[i]['dte'] == options[j]['dte']:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "options = [\n",
    "    {'strike_price': 100, 'dte': 30},\n",
    "    {'strike_price': 105, 'dte': 30},\n",
    "    {'strike_price': 110, 'dte': 30},\n",
    "    {'strike_price': 115, 'dte': 30},\n",
    "    {'strike_price': 120, 'dte': 30},\n",
    "    {'strike_price': 0, 'dte': 0},  # เปลี่ยนค่าเป็น 0\n",
    "]\n",
    "\n",
    "options = [\n",
    "    {'strike_price': 0, 'dte': 0},\n",
    "    {'strike_price': 120, 'dte': 30},\n",
    "    {'strike_price': 150, 'dte': 30},\n",
    "    {'strike_price': 110, 'dte': 30},\n",
    "    {'strike_price': 105, 'dte': 30},\n",
    "    {'strike_price': 100, 'dte': 30},  # เปลี่ยนค่าเป็น 0\n",
    "]\n",
    "\n",
    "\n",
    "# ปรับ threshold\n",
    "threshold = 5\n",
    "\n",
    "adjacency_matrix = create_adjacency_matrix(options, threshold)\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array(\n",
    "    [[1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a random numpy array with shape (2, 20, 6)\n",
    "random_array = np.random.rand(2, 20, 6)\n",
    "\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.random.rand(2, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array[:, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = [\"c_bid\", \"c_ask\", \"c_volume\", \"p_bid\", \"p_ask\", \"p_volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList.index(\"c_ask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f77a7efb8cf15d18a0cd6bbc71a8985efbc57e2467f435a53ada42728ce0a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
