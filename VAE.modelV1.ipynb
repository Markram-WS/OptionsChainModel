{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/generative/vae/\n",
    "#https://keras.io/examples/generative/molecule_generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "#================== initialization ==================\n",
    "LATENT_DIM = 128\n",
    "VAE_LR = 5e-4\n",
    "PARQUET_PATH = './data/OptionsEOD.parquet'\n",
    "SCALER_PATH = './data/scaler.gz'\n",
    "SCALER_COL  = ['DTE','INTRINSIC_VALUE','C_VOLUME',\t'C_BID',\t'C_ASK',\t'P_BID',\t'P_ASK',\t'P_VOLUME' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load scaler\n",
    "scaler = MinMaxScaler()\n",
    "PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_PATH) if 'PartitionDate' in d]\n",
    "for i,partdate in enumerate(PartitionDate) :\n",
    "    df = pd.read_parquet(PARQUET_PATH,engine='pyarrow'\n",
    "                                 , filters=[('PartitionDate', '=', partdate)]\n",
    "                                )\n",
    "    df['P_VOLUME'] = df['P_VOLUME'].fillna(0)\n",
    "    df['C_VOLUME'] = df['C_VOLUME'].fillna(0)\n",
    "    break\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "df_tf = scaler.transform(df[SCALER_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56542, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - kl_loss: 1.9520 - loss: 45.7004 - reconstruction_loss: 43.7484"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No loss to compute. Provide a `loss` argument in `compile()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m x_test_noisy \u001b[38;5;241m=\u001b[39m x_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, size\u001b[38;5;241m=\u001b[39mx_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# # Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# # Generate images from noise data\u001b[39;00m\n\u001b[1;32m     20\u001b[0m reconstructed_images \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mpredict(x_test_noisy)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py:327\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    325\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mcast(loss, dtype\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mfloatx()))\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_empty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(losses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo loss to compute. Provide a `loss` argument in `compile()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(losses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    331\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m losses[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: No loss to compute. Provide a `loss` argument in `compile()`."
     ]
    }
   ],
   "source": [
    "from src.model import OptionChainGenerator\n",
    "from src.layer import encoder, decoder\n",
    "\n",
    "model = OptionChainGenerator(\n",
    "    encoder(latent_dim = LATENT_DIM, \n",
    "            input_shape= , \n",
    "            gconv_units = [64, 128], \n",
    "            dense_units = [256, 128], \n",
    "            dropout_rate= 0.1,\n",
    "            output_dim  = \n",
    "           ), \n",
    "    decoder(latent_dim  = LATENT_DIM , \n",
    "            output_shape= ,\n",
    "            dense_units = [128, 256],\n",
    "            dropout_rate= 0.1\n",
    "           )\n",
    ")\n",
    "model.summery()\n",
    "vae_optimizer = tf.keras.optimizers.Adam(learning_rate=VAE_LR)\n",
    "model.compile(vae_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== train model ==================\n",
    "history = model.fit([feature_tensor], epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_adjacency_matrix(options, threshold=25):\n",
    "    \"\"\"\n",
    "    สร้าง adjacency matrix สำหรับ Options Chain โดยใช้ความใกล้เคียงของ strike price และ DTE\n",
    "    \"\"\"\n",
    "    num_options = len(options)\n",
    "    adjacency_matrix = np.zeros((num_options, num_options))\n",
    "\n",
    "    for i in range(num_options):\n",
    "        for j in range(i, num_options):\n",
    "            # พิจารณาเชื่อมโยงระหว่าง options หาก strike price ต่างกันไม่เกิน threshold และ DTE เท่ากัน\n",
    "            if abs(options[i]['strike_price'] - options[j]['strike_price']) <= threshold and options[i]['dte'] == options[j]['dte']:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "options = [\n",
    "    {'strike_price': 100, 'dte': 30},\n",
    "    {'strike_price': 105, 'dte': 30},\n",
    "    {'strike_price': 110, 'dte': 30},\n",
    "    {'strike_price': 115, 'dte': 30},\n",
    "    {'strike_price': 120, 'dte': 30},\n",
    "    {'strike_price': 0, 'dte': 0},  # เปลี่ยนค่าเป็น 0\n",
    "]\n",
    "\n",
    "options = [\n",
    "    {'strike_price': 0, 'dte': 0},\n",
    "    {'strike_price': 120, 'dte': 30},\n",
    "    {'strike_price': 150, 'dte': 30},\n",
    "    {'strike_price': 110, 'dte': 30},\n",
    "    {'strike_price': 105, 'dte': 30},\n",
    "    {'strike_price': 100, 'dte': 30},  # เปลี่ยนค่าเป็น 0\n",
    "]\n",
    "\n",
    "\n",
    "# ปรับ threshold\n",
    "threshold = 5\n",
    "\n",
    "adjacency_matrix = create_adjacency_matrix(options, threshold)\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array(\n",
    "    [[1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "A[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_variable_name(variable):\n",
    "    for name, value in globals().items():\n",
    "        if value is variable:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "leo = ['a', 'b']\n",
    "var_name = get_variable_name(leo)\n",
    "print(var_name)  # Ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f77a7efb8cf15d18a0cd6bbc71a8985efbc57e2467f435a53ada42728ce0a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
