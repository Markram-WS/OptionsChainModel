{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/generative/vae/\n",
    "#https://keras.io/examples/generative/molecule_generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install --upgrade pip\n",
    "# !pip install pydot\n",
    "# !apt-get install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try creatmodel without volumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil,random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output,display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from src.model import Sampling\n",
    "#================== initialization ==================\n",
    "currentTM=dt.datetime.now().strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "PROJECT = \"testVAEModel\"\n",
    "LATENT_DIM = 32\n",
    "VAE_LR = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PARQUET_PATH = './data/OptionsEOD_STG.parquet'\n",
    "SCALER_PATH = './data/scaler/scaler.gz'\n",
    "UNIQUE_KEYS = ['QUOTE_DATE','SYMBOL','EXPIRE_DATE']\n",
    "SCALER_COL  = ['DTE','INTRINSIC_VALUE', 'TOTAL_VOLUME',\t'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK',\t'P_VOLUME' ]\n",
    "MODEL_PATH = \"./models/\"\n",
    "H5_PATH = './data/OptTrainData/'\n",
    "DISPLAY = False\n",
    "WANDB_LOG = True\n",
    "RESUME = False\n",
    "\n",
    "Scaler = joblib.load(SCALER_PATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwasan-sinlapa\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/workspace/OptionsChainModel/wandb/run-20240708_130909-sxuy9fis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wasan-sinlapa/testVAEModel/runs/sxuy9fis/workspace' target=\"_blank\">2024-07-08T130906</a></strong> to <a href='https://wandb.ai/wasan-sinlapa/testVAEModel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wasan-sinlapa/testVAEModel' target=\"_blank\">https://wandb.ai/wasan-sinlapa/testVAEModel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wasan-sinlapa/testVAEModel/runs/sxuy9fis/workspace' target=\"_blank\">https://wandb.ai/wasan-sinlapa/testVAEModel/runs/sxuy9fis/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes = f\"\"\"\n",
    "test Run use_bias set false , no tranfrom\n",
    "\"\"\"\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "CONFIG = {\"latent_dim\":LATENT_DIM,\n",
    "          \"learning_rate\": VAE_LR,\n",
    "          \"epochs\": EPOCHS,\n",
    "          \"batch_size\": BATCH_SIZE,\n",
    "          \"architecture\": \"VAE\",\n",
    "          \"dataset\": \"OptionsChaine\",\n",
    "          \"encoder_dense_units\":[128,64],\n",
    "          \"encoder_dropout_rate\":0.2,\n",
    "          \"decoder_dense_units\":[64, 128],\n",
    "          \"decoder_dropout_rate\":0.2,\n",
    "          \"use_bias\":False,\n",
    "          \"transform\":True\n",
    "           }\n",
    "\n",
    "if WANDB_LOG :\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=PROJECT, \n",
    "                     name=currentTM, \n",
    "                     config=CONFIG,\n",
    "                     notes=notes\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "\n",
    "# from IPython.display import clear_output,display, HTML\n",
    "# import numpy as np\n",
    "# #load scaler\n",
    "# scaler = MinMaxScaler()\n",
    "# PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_PATH) if 'PartitionDate' in d]\n",
    "# random.shuffle(PartitionDate)\n",
    "# scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "\n",
    "# for i,partdate in enumerate(PartitionDate) :\n",
    "#     df = pd.read_parquet(PARQUET_PATH,engine='pyarrow'\n",
    "#                                  , filters=[('PartitionDate', '=', partdate)]\n",
    "#                                 )\n",
    "#     df['P_VOLUME'] = df['P_VOLUME'].fillna(0)\n",
    "#     df['C_VOLUME'] = df['C_VOLUME'].fillna(0)\n",
    "#     DATA  = np.empty((0,) + (20,9) ) \n",
    "#     for opt_id in np.unique( df[[\"OPTIONS_ID\"]].values):\n",
    "#         df_filter  = df[df[\"OPTIONS_ID\"]==opt_id]\n",
    "#         if len(df_filter) == 20:\n",
    "#             DATA = np.vstack((DATA ,[scaler.transform(df_filter[SCALER_COL])]))\n",
    "#         else:\n",
    "#             #print( len(df_filter) )\n",
    "#             #display(HTML(df_filter[['STRIKE']+SCALER_COL].to_html()))\n",
    "#             pass\n",
    "            \n",
    "#     ## Save the NumPy array to an HDF5 file\n",
    "#     # with h5py.File(H5_PATH+f\"{partdate}.h5\", 'w') as f:\n",
    "#     #     dset = f.create_dataset(f'{partdate}', data=DATA, chunks=True , compression='gzip')\n",
    "\n",
    "#     print(f\"[Processing] {partdate}, {round(((i+1)/len(PartitionDate))*100,2)}%     \",end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the NumPy array to an HDF5 file\n",
    "# with h5py.File(H5_PATH, 'w') as f:\n",
    "#     #dset = f.create_dataset('dataset', data=DATA, chunks=True, compression='gzip')\n",
    "#     #test\n",
    "#     dset = f.create_dataset('dataset', data=DATA, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import OptionChainGenerator\n",
    "from src.layer import encoder, decoder\n",
    "\n",
    "model = OptionChainGenerator(\n",
    "    encoder(latent_dim = LATENT_DIM, \n",
    "            input_shape= (32,3), \n",
    "            dense_units = CONFIG[\"encoder_dense_units\"], \n",
    "            dropout_rate= CONFIG[\"encoder_dropout_rate\"],\n",
    "            use_bias=CONFIG[\"use_bias\"]\n",
    "           ), \n",
    "    decoder(latent_dim  = LATENT_DIM , \n",
    "            output_shape= (32,1),\n",
    "            dense_units = CONFIG[\"decoder_dense_units\"],\n",
    "            dropout_rate= CONFIG[\"decoder_dropout_rate\"],\n",
    "            use_bias=CONFIG[\"use_bias\"]\n",
    "           )\n",
    ")\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return 0.0\n",
    "    \n",
    "vae_optimizer = tf.keras.optimizers.Adam(learning_rate=VAE_LR)\n",
    "model.compile(vae_optimizer )#, loss=dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## show model ######################\n",
    "if DISPLAY :\n",
    "    from tensorflow.keras.utils import model_to_dot\n",
    "    from IPython.display import SVG, display\n",
    "    \n",
    "    def display_model(model, width=1024, height=512):\n",
    "        dot = model_to_dot(model, show_shapes=True, show_layer_names=True)\n",
    "        svg_data = dot.create(prog='dot', format='svg').decode(\"utf-8\")\n",
    "        svg_html = f'<div style=\"width:{width}px;height:{height}px;\">{svg_data}</div>'\n",
    "        display(HTML(svg_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage:\n",
    "## Display the encoder model with reduced size\n",
    "if DISPLAY :\n",
    "    display_model(model.encoder, width=1024, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY :\n",
    "    display_model(model.decoder, width=2500, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== loadmodel ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_path = MODEL_PATH+f'{PROJECT}'\n",
    "if not RESUME :\n",
    "    if os.path.exists(model_path) :\n",
    "        shutil.rmtree(model_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    model.encoder.save(model_path+f'/'+f'encoder.keras') \n",
    "    model.decoder.save(model_path+f'/'+f'decoder.keras') \n",
    "else:\n",
    "    model.encoder = load_model(model_path+'/'+f'encoder.keras') \n",
    "    model.decoder = load_model(model_path+'/'+f'decoder.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== train model ==================\n",
    "PartitionDate = [ d[:-3] for d in  os.listdir(H5_PATH)]\n",
    "random.shuffle(PartitionDate)\n",
    "\n",
    "STOP_MODEL = False\n",
    "STACK_DATA = np.empty((0,) + (32,9) ) #init STACK_DATA\n",
    "for partdate in PartitionDate[:] :\n",
    "    clear_output(wait=False)\n",
    "    DATA = []\n",
    "    with h5py.File(H5_PATH+partdate+\".h5\", 'r') as f:\n",
    "        DATA = f[partdate][:]\n",
    "    data_shape = DATA.shape\n",
    "    ###transform\n",
    "    if CONFIG['transform'] :\n",
    "        DATA = Scaler.transform(DATA.reshape(-1,data_shape[-1]))\n",
    "        DATA = DATA.reshape(data_shape)\n",
    "    DATA = np.vstack((DATA ,STACK_DATA))\n",
    "    if len(DATA) < 64 :\n",
    "        #stack data\n",
    "        STACK_DATA = np.vstack((STACK_DATA ,DATA))\n",
    "    else: \n",
    "        # if DATA.isna().sum().sum() > 0:\n",
    "        #     print(\"Data contains NaNs. Please handle them before scaling.\")\n",
    "        STACK_DATA = np.empty((0,) + (32,9) )\n",
    "        X = DATA[:, :, :3]  # เลือกข้อมูลแถวแรกถึงแถวที่ 3 สำหรับ X\n",
    "        Y = DATA[:, :, 3:]  # เลือกข้อมูลแถวที่ 3 เป็นต้นไปสำหรับ Y\n",
    "        x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        random.shuffle(PartitionDate)\n",
    "        tf.keras.backend.clear_session() \n",
    "        history = model.fit(x_train , y_train, epochs=CONFIG['epochs'], batch_size=BATCH_SIZE, validation_data=(x_val, y_val) )\n",
    "        #history = model.fit(x_train , y_train, epochs=5, batch_size=BATCH_SIZE )\n",
    "        if  np.isnan(  np.average( history.history['kl_loss'] )  ) or np.isnan(  np.average( history.history['val_kl_loss'] )  ):\n",
    "            STOP_MODEL = True \n",
    "            print(x_train)\n",
    "            print(\"---\")\n",
    "            print(x_val)\n",
    "            print(\"=============\")\n",
    "        if WANDB_LOG :\n",
    "            LogKeys = history.history.keys()\n",
    "            LogVal={}\n",
    "            for k in LogKeys:  \n",
    "                LogVal[k] = np.average(  history.history[k] )\n",
    "            wandb.log(LogVal, commit=True)\n",
    "        \n",
    "    if STOP_MODEL :\n",
    "        break\n",
    "    \n",
    "            \n",
    "    model.encoder.save(model_path+f'/'+f'encoder.keras') \n",
    "    model.decoder.save(model_path+f'/'+f'decoder.keras') \n",
    "if WANDB_LOG : wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================== predict ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartitionDate = [ d[:-3] for d in  os.listdir(H5_PATH)]\n",
    "random.shuffle(PartitionDate)\n",
    "for partdate in PartitionDate[:1] :\n",
    "    DATA = []\n",
    "    with h5py.File(H5_PATH+partdate+\".h5\", 'r') as f:\n",
    "        DATA = f[partdate][:]\n",
    "    data_shape = DATA.shape\n",
    "    if CONFIG['transform'] :\n",
    "        DATA_TF = Scaler.transform(DATA.reshape(-1,data_shape[-1]))\n",
    "        DATA_TF = DATA_TF.reshape(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DATA_TF[:, :, :3][:1]\n",
    "# X data\n",
    "df = pd.DataFrame(\n",
    "    DATA[:, :, :3][:1].reshape(32, 3), \n",
    "    columns=SCALER_COL[:3])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, log_var = model.encoder(X) \n",
    "z = Sampling()([z_mean, log_var])\n",
    "decode_data = model.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================= _compute_loss =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated_data = [c_bid, c_ask, c_volume, p_bid, p_ask, p_volume]\n",
    "colList = [\"c_bid\", \"c_ask\", \"c_volume\", \"p_bid\", \"p_ask\", \"p_volume\"]\n",
    "generated_data = decode_data[3:]\n",
    "z_mean    = z_mean\n",
    "z_log_var = log_var\n",
    "Y_real    = DATA[:, :, 3:][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.188e+01, 1.216e+01, 1.100e+01, 9.000e-02, 1.000e-01, 6.060e+02])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for  col,genData in zip(colList,generated_data):\n",
    "    print( colList.index(col),col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtract_genData = genData - tf.cast(tf.expand_dims(Y_real[:, :, colList.index(col)], axis=-1)\n",
    "        , tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_values_total = []\n",
    "reconstruction_values_total.append( tf.reduce_mean( tf.square(subtract_genData)   ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_var = tf.clip_by_value(log_var, -1.0, 1.0)\n",
    "kl_loss = -0.5 * tf.reduce_sum(1 + log_var - tf.square(z_mean) - tf.exp(log_var), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=19854.121>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(reconstruction_values_total + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================= inverse_transform ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 0\n",
    "decode_data = [tf.zeros([1, 32, 1])]*3 + decode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_decode = Scaler.inverse_transform(\n",
    "    np.array([d.numpy().reshape(-1) for d in decode_data]).transpose()\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_BID</th>\n",
       "      <th>C_ASK</th>\n",
       "      <th>C_VOLUME</th>\n",
       "      <th>P_BID</th>\n",
       "      <th>P_ASK</th>\n",
       "      <th>P_VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>112.805359</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>94.043495</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144.180679</td>\n",
       "      <td>75.689438</td>\n",
       "      <td>588.284241</td>\n",
       "      <td>51.924221</td>\n",
       "      <td>61.831406</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.913605</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>45.765572</td>\n",
       "      <td>220.349365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>85.750114</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>38.844898</td>\n",
       "      <td>52.346127</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>114.237602</td>\n",
       "      <td>563.369873</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>97.664665</td>\n",
       "      <td>443.883575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72.891563</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>303.591736</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>149.589447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73.816498</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>703.170227</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>143.152863</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>97.970665</td>\n",
       "      <td>100.458321</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>94.341377</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>160.380630</td>\n",
       "      <td>110.638863</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>66.755714</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>553.159912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76.275078</td>\n",
       "      <td>127.448189</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.856621</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>120.379005</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>86.492844</td>\n",
       "      <td>125.878479</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>473.519379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>167.565994</td>\n",
       "      <td>91.948364</td>\n",
       "      <td>425.648376</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>195.688431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75.851151</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>453.037140</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>44.221592</td>\n",
       "      <td>101.365379</td>\n",
       "      <td>537.670410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108.571625</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>84.494766</td>\n",
       "      <td>776.409607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>97.675636</td>\n",
       "      <td>128.845749</td>\n",
       "      <td>288.887756</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>949.410828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>140.199005</td>\n",
       "      <td>108.220490</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>83.595985</td>\n",
       "      <td>170.656952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>96.188705</td>\n",
       "      <td>184.079971</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>76.560249</td>\n",
       "      <td>384.525452</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>79.168892</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>123.836700</td>\n",
       "      <td>58.214607</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>110.753983</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>88.321892</td>\n",
       "      <td>124.496254</td>\n",
       "      <td>259.753174</td>\n",
       "      <td>67.269554</td>\n",
       "      <td>66.503479</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>205.919067</td>\n",
       "      <td>131.150848</td>\n",
       "      <td>344.454315</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>62.961605</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>108.392891</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>132.172531</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>195.406647</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>341.379364</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>95.299805</td>\n",
       "      <td>290.878723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>84.489594</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>45.864857</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>328.533569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>297.960846</td>\n",
       "      <td>60.932690</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>960.746887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>69.049614</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>487.928986</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>70.957184</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>90.952919</td>\n",
       "      <td>117.545464</td>\n",
       "      <td>79.222069</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>56.783310</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>60.880363</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>354.377869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>68.616890</td>\n",
       "      <td>142.331879</td>\n",
       "      <td>229.667938</td>\n",
       "      <td>85.868103</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>264.548553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>152.459076</td>\n",
       "      <td>70.390205</td>\n",
       "      <td>57.281818</td>\n",
       "      <td>34.165512</td>\n",
       "      <td>35.460060</td>\n",
       "      <td>87.271248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C_BID       C_ASK    C_VOLUME       P_BID       P_ASK    P_VOLUME\n",
       "0    68.616890  112.805359   57.281818   94.043495   35.460060   87.271248\n",
       "1   144.180679   75.689438  588.284241   51.924221   61.831406   87.271248\n",
       "2    99.913605   70.390205   57.281818   34.165512   45.765572  220.349365\n",
       "3    68.616890   85.750114   57.281818   38.844898   52.346127   87.271248\n",
       "4    68.616890  114.237602  563.369873   34.165512   97.664665  443.883575\n",
       "5    72.891563   70.390205  303.591736   34.165512   35.460060  149.589447\n",
       "6    73.816498   70.390205  703.170227   34.165512  143.152863   87.271248\n",
       "7    97.970665  100.458321   57.281818   34.165512   94.341377   87.271248\n",
       "8   160.380630  110.638863   57.281818   66.755714   35.460060  553.159912\n",
       "9    76.275078  127.448189   57.281818   34.165512   35.856621   87.271248\n",
       "10  120.379005   70.390205   86.492844  125.878479   35.460060  473.519379\n",
       "11  167.565994   91.948364  425.648376   34.165512   35.460060  195.688431\n",
       "12   75.851151   70.390205  453.037140   34.165512   35.460060   87.271248\n",
       "13   68.616890   70.390205   57.281818   44.221592  101.365379  537.670410\n",
       "14  108.571625   70.390205   57.281818   34.165512   84.494766  776.409607\n",
       "15   97.675636  128.845749  288.887756   34.165512   35.460060  949.410828\n",
       "16   68.616890  140.199005  108.220490   34.165512   83.595985  170.656952\n",
       "17   96.188705  184.079971   57.281818   34.165512   35.460060   87.271248\n",
       "18   68.616890   76.560249  384.525452   34.165512   35.460060   87.271248\n",
       "19   79.168892   70.390205  123.836700   58.214607   35.460060   87.271248\n",
       "20  110.753983   70.390205   57.281818   34.165512   35.460060   87.271248\n",
       "21   88.321892  124.496254  259.753174   67.269554   66.503479   87.271248\n",
       "22  205.919067  131.150848  344.454315   34.165512   62.961605   87.271248\n",
       "23  108.392891   70.390205  132.172531   34.165512   35.460060   87.271248\n",
       "24  195.406647   70.390205  341.379364   34.165512   95.299805  290.878723\n",
       "25   68.616890   84.489594   57.281818   45.864857   35.460060  328.533569\n",
       "26   68.616890   70.390205  297.960846   60.932690   35.460060  960.746887\n",
       "27   69.049614   70.390205  487.928986   34.165512   70.957184   87.271248\n",
       "28   90.952919  117.545464   79.222069   34.165512   56.783310   87.271248\n",
       "29   68.616890   70.390205   57.281818   60.880363   35.460060  354.377869\n",
       "30   68.616890  142.331879  229.667938   85.868103   35.460060  264.548553\n",
       "31  152.459076   70.390205   57.281818   34.165512   35.460060   87.271248"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    invert_decode[:,3:], \n",
    "    columns=SCALER_COL[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3079178945.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[86], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    =====================================================================\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f77a7efb8cf15d18a0cd6bbc71a8985efbc57e2467f435a53ada42728ce0a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
