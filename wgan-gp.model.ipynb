{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/generative/vae/\n",
    "#https://keras.io/examples/generative/molecule_generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/app/logs/wgangpModel/20240805-040909/train': Directory not empty\n",
      "rm: cannot remove '/app/logs/wgangpModel/20240805-040909/validation': Directory not empty\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -r /app/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 04:30:36.532677: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-05 04:30:36.538656: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-05 04:30:36.554043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 04:30:36.576254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 04:30:36.583097: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 04:30:36.602193: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 04:30:37.834565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os,shutil,random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output,display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== initialization ==================\n",
    "#best LR = 1e-4,EPOCHS = 10,\"discriminator_extra_steps\":1\n",
    "#best LR = 1e-4,EPOCHS = 15,\"discriminator_extra_steps\":1\n",
    "\n",
    "currentTM=dt.datetime.now().strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "PROJECT = \"wgangpModel\"\n",
    "LATENT_DIM = 16\n",
    "LR = 1e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PARQUET_PATH = './data/OptionsEOD_STG.parquet'\n",
    "SCALER_PATH = './data/scaler/scaler.gz'\n",
    "UNIQUE_KEYS = ['QUOTE_DATE','SYMBOL','EXPIRE_DATE']\n",
    "SCALER_COL  = ['UNDERLYING_LAST','STRIKE','STRIKE_DISTANCE','INTRINSIC_VALUE','DTE','TOTAL_VOLUME','C_VEGA','P_VEGA',\t'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK', 'P_VOLUME' ]\n",
    "MODEL_PATH = \"./models/\"\n",
    "H5_PATH = './data/OptTrainData/'\n",
    "STACK_DATA_SHAPE = np.empty((0,) + (16, len( SCALER_COL)  ) ) \n",
    "\n",
    "WANDB_LOG = True\n",
    "RESUME = False\n",
    "SUMMARY = True\n",
    "log_dir = f\"/app/logs/{PROJECT}/\"+dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "Scaler = joblib.load(SCALER_PATH )\n",
    "\n",
    "#DISPLAY = ['map','summary',None]\n",
    "DISPLAY = 'summary'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##['UNDERLYING_LAST','STRIKE','STRIKE_DISTANCE','INTRINSIC_VALUE','DTE','TOTAL_VOLUME','C_VEGA','P_VEGA',\t'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK', 'P_VOLUME' ]\n",
    "select_x = [i for i,c in  enumerate(SCALER_COL) if c in ['DTE','INTRINSIC_VALUE','C_VEGA','P_VEGA'] ]\n",
    "select_y = [i for i,c in enumerate(SCALER_COL) if c in ['C_BID','C_ASK',  'P_BID',\t'P_ASK'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwasan-sinlapa\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabe93d4553747ae92520c0fba3d53d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113537544446848, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/workspace/OptionsChainModel/wandb/run-20240805_043040-xspby9k2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wasan-sinlapa/wgangpModel/runs/xspby9k2' target=\"_blank\">2024-08-05T043038</a></strong> to <a href='https://wandb.ai/wasan-sinlapa/wgangpModel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wasan-sinlapa/wgangpModel' target=\"_blank\">https://wandb.ai/wasan-sinlapa/wgangpModel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wasan-sinlapa/wgangpModel/runs/xspby9k2' target=\"_blank\">https://wandb.ai/wasan-sinlapa/wgangpModel/runs/xspby9k2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes = f\"\"\"\n",
    "test Run use_bias set false , no tranfrom\n",
    "\"\"\"\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "CONFIG = {\n",
    "          \"learning_rate\": LR,\n",
    "          \"epochs\": EPOCHS,\n",
    "          \"batch_size\": BATCH_SIZE,\n",
    "          \"architecture\": \"wgangp\",\n",
    "          \"dataset\": \"OptionsChaine\",\n",
    "          \"generator_dense_units\":[128,64,32],\n",
    "          \"generator_dropout_rate\":0.2,\n",
    "          \"discriminator_dense_units\":[32,64,128],\n",
    "          \"discriminator_dropout_rate\":0.2,\n",
    "          \"use_bias\":False,\n",
    "          \"use_dropout\":True,\n",
    "          \"use_bn\":True,\n",
    "          \"transform\":True,\n",
    "          \"discriminator_extra_steps\":1\n",
    "          \"x_col\":select_x,\n",
    "          \"y_col\":select_y,\n",
    "           }\n",
    "\n",
    "if WANDB_LOG :\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=PROJECT, \n",
    "                     name=currentTM, \n",
    "                     config=CONFIG,\n",
    "                     notes=notes\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wgangp.model import OptionChainGenerator\n",
    "from src.wgangp.layer import generator, discriminator\n",
    "\n",
    "model = OptionChainGenerator(\n",
    "    discriminator = discriminator(\n",
    "            input_shape= (16,len(select_y) ), \n",
    "            dense_units = CONFIG[\"generator_dense_units\"], \n",
    "            dropout_rate= CONFIG[\"generator_dropout_rate\"],\n",
    "            use_bias=CONFIG[\"use_bias\"],\n",
    "            use_dropout=CONFIG[\"use_dropout\"],\n",
    "            use_bn=CONFIG[\"use_bn\"]\n",
    "           ), \n",
    "    generator = generator(\n",
    "            input_dim = (16,len(select_y) ),\n",
    "            output_dim = (16,len(select_x) ) ,\n",
    "            dense_units = CONFIG[\"discriminator_dense_units\"],\n",
    "            dropout_rate= CONFIG[\"discriminator_dropout_rate\"],\n",
    "            use_bias=CONFIG[\"use_bias\"],\n",
    "            use_dropout=CONFIG[\"use_dropout\"],\n",
    "            use_bn=CONFIG[\"use_bn\"]\n",
    "           ),\n",
    "    discriminator_extra_steps = CONFIG[\"discriminator_extra_steps\"]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    d_optimizer = tf.optimizers.Adam(\n",
    "    learning_rate=LR, beta_1=0.5, beta_2=0.9\n",
    "    ),\n",
    "    g_optimizer = tf.optimizers.Adam(\n",
    "    learning_rate=LR, beta_1=0.5, beta_2=0.9\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## show model ######################\n",
    "if DISPLAY == 'map' :\n",
    "    from tensorflow.keras.utils import model_to_dot\n",
    "    from IPython.display import SVG, display\n",
    "    \n",
    "    def display_model(model, width=1024, height=512):\n",
    "        dot = model_to_dot(model, show_shapes=True, show_layer_names=True)\n",
    "        svg_data = dot.create(prog='dot', format='svg').decode(\"utf-8\")\n",
    "        svg_html = f'<div style=\"width:{width}px;height:{height}px;\">{svg_data}</div>'\n",
    "        display(HTML(svg_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"generator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"generator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_x_data        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_x_data[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-32           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ Conv2D-32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_1       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-64           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ Conv2D-64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-128          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ Conv2D-128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Reshape-output      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_x_data        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_x_data[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-32           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,152\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ Conv2D-32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_1       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-64           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m18,432\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ Conv2D-64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m1\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-128          │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m73,728\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ Conv2D-128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m2\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │    \u001b[38;5;34m131,136\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Reshape-output      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,344</span> (880.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,344\u001b[0m (880.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,896</span> (878.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m224,896\u001b[0m (878.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Example usage:\n",
    "## Display the generator model with reduced size\n",
    "if DISPLAY == 'map' :\n",
    "    display_model(model.generator, width, height=512)\n",
    "if DISPLAY == 'summary' :\n",
    "    model.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"discriminator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"discriminator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_y_data        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_y_data[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ zero_padding2d      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ zero_padding2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-logic        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,121</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_y_data        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_y_data[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ zero_padding2d      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m1,152\u001b[0m │ zero_padding2d[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m73,728\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │     \u001b[38;5;34m18,432\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5120\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5120\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv2D-logic        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │      \u001b[38;5;34m5,121\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,329</span> (388.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,329\u001b[0m (388.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,881</span> (386.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,881\u001b[0m (386.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DISPLAY == 'map' :\n",
    "    display_model(model.discriminator, width=2500, height=512)\n",
    "if DISPLAY == 'summary' :\n",
    "    model.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================== loadmodel ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_path = MODEL_PATH+f'{PROJECT}'\n",
    "if not RESUME :\n",
    "    if os.path.exists(model_path) :\n",
    "        shutil.rmtree(model_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    model.generator.save(model_path+f'/'+f'generator.keras') \n",
    "    model.discriminator.save(model_path+f'/'+f'discriminator.keras') \n",
    "else:\n",
    "    model.generator = load_model(model_path+'/'+f'generator.keras') \n",
    "    model.discriminator = load_model(model_path+'/'+f'discriminator.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 248ms/step - discriminator_loss: -0.1857 - generator_loss: -13.8122 - val_discriminator_loss: -2.1567 - val_generator_loss: -9.1525\n",
      "Epoch 2/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - discriminator_loss: -0.5425 - generator_loss: -14.6118 - val_discriminator_loss: -3.0100 - val_generator_loss: -9.2752\n",
      "Epoch 3/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 233ms/step - discriminator_loss: 0.1799 - generator_loss: -15.1429 - val_discriminator_loss: -2.9273 - val_generator_loss: -11.3066\n",
      "Epoch 4/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 234ms/step - discriminator_loss: 0.1504 - generator_loss: -15.4370 - val_discriminator_loss: -3.2714 - val_generator_loss: -11.8251\n",
      "Epoch 5/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - discriminator_loss: 0.0952 - generator_loss: -15.3564 - val_discriminator_loss: -3.1226 - val_generator_loss: -12.4682\n",
      "Epoch 6/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - discriminator_loss: 0.1529 - generator_loss: -14.9736 - val_discriminator_loss: -3.3416 - val_generator_loss: -12.4319\n",
      "Epoch 7/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - discriminator_loss: 0.0101 - generator_loss: -15.3619 - val_discriminator_loss: -2.7332 - val_generator_loss: -13.3005\n",
      "Epoch 8/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - discriminator_loss: -0.0056 - generator_loss: -15.2150 - val_discriminator_loss: -2.3986 - val_generator_loss: -13.6164\n",
      "Epoch 9/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 229ms/step - discriminator_loss: -0.0307 - generator_loss: -15.1866 - val_discriminator_loss: -2.9690 - val_generator_loss: -12.8468\n",
      "Epoch 10/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - discriminator_loss: 0.1347 - generator_loss: -14.6272 - val_discriminator_loss: -2.0472 - val_generator_loss: -13.4832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>discriminator_loss</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>generator_loss</td><td>█▇▇▇▆▆▆▆▆▆▆▅▆▆▅▅▅▄▅▅▄▅▄▄▄▄▄▄▄▄▃▄▃▂▂▂▂▃▂▁</td></tr><tr><td>val_discriminator_loss</td><td>▇▆▆▅▅▅▅▅▅▅▅▅▆▅▅▅▅▆▆▆▅▄▆▆▅█▆▆▅▅▅▅▆▅▅▅▅▅▅▁</td></tr><tr><td>val_generator_loss</td><td>█▇██▇▇▇▆▇▆▇▆▇▇▅▅▆▄▆▅▅▆▄▄▃▃▄▄▅▅▃▄▃▂▂▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>discriminator_loss</td><td>-0.01798</td></tr><tr><td>generator_loss</td><td>-14.9895</td></tr><tr><td>val_discriminator_loss</td><td>-2.79776</td></tr><tr><td>val_generator_loss</td><td>-11.97063</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-08-05T043038</strong> at: <a href='https://wandb.ai/wasan-sinlapa/wgangpModel/runs/xspby9k2' target=\"_blank\">https://wandb.ai/wasan-sinlapa/wgangpModel/runs/xspby9k2</a><br/> View project at: <a href='https://wandb.ai/wasan-sinlapa/wgangpModel' target=\"_blank\">https://wandb.ai/wasan-sinlapa/wgangpModel</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240805_043040-xspby9k2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================== train model ==================\n",
    "PartitionDate = [ d[:-3] for d in  os.listdir(H5_PATH)]\n",
    "random.shuffle(PartitionDate)\n",
    "#SET MODEL VAR\n",
    "STACK_DATA = STACK_DATA_SHAPE \n",
    "#INIT MODEL VAR\n",
    "STOP_MODEL = False\n",
    "\n",
    "#set PartitionDate[:] for limit range\n",
    "for partdate in PartitionDate[:] :\n",
    "    clear_output(wait=False)\n",
    "    DATA = []\n",
    "    with h5py.File(H5_PATH+partdate+\".h5\", 'r') as f:\n",
    "        DATA = f[partdate][:]\n",
    "    data_shape = DATA.shape\n",
    "    ###transform\n",
    "    if CONFIG['transform'] :\n",
    "        DATA = Scaler.transform(DATA.reshape(-1,data_shape[-1]))\n",
    "        DATA = DATA.reshape(data_shape)\n",
    "        #! เช็ตปัญหาการ แปลง shape\n",
    "        #inv.tran data ไม่ได้ค่าเดิม\n",
    "    DATA = np.vstack((DATA ,STACK_DATA))\n",
    "\n",
    "    if len(DATA) < 64 :\n",
    "        #stack data\n",
    "        STACK_DATA = np.vstack((STACK_DATA ,DATA))\n",
    "    else: \n",
    "        STACK_DATA = np.empty((0,) + data_shape[1:] )\n",
    "        X = DATA[:, :, select_x]  # เลือกข้อมูล select_x สำหรับ X\n",
    "        Y = DATA[:, :, select_y]  # เลือกข้อมูล select_y เสำหรับ Y\n",
    "        x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        random.shuffle(PartitionDate)\n",
    "        tf.keras.backend.clear_session() \n",
    "        history = model.fit(x_train , y_train, epochs=CONFIG['epochs'], batch_size=BATCH_SIZE, validation_data=(x_val, y_val) ,callbacks=[tensorboard_callback])\n",
    "        if  np.isnan(  np.average( history.history['generator_loss'] )  ) or np.isnan(  np.average( history.history['discriminator_loss'] )  ):\n",
    "            STOP_MODEL = True \n",
    "    \n",
    "        if WANDB_LOG :\n",
    "            LogKeys = history.history.keys()\n",
    "            LogVal={}\n",
    "            for k in LogKeys:  \n",
    "                LogVal[k] = np.average(  history.history[k] )\n",
    "            wandb.log(LogVal, commit=True)\n",
    "    if STOP_MODEL :\n",
    "        break\n",
    "    \n",
    "            \n",
    "    model.generator.save(model_path+f'/'+f'generator.keras') \n",
    "    model.discriminator.save(model_path+f'/'+f'discriminator.keras') \n",
    "if WANDB_LOG : wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2094489582.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    `====================================================\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "`===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_num = 1\n",
    "\n",
    "\n",
    "partd = '2011-12'\n",
    "with h5py.File(H5_PATH+partd+\".h5\", 'r') as f:\n",
    "    d = f[partd][:]\n",
    "d=Scaler.inverse_transform(\n",
    "        d[10]\n",
    "    )\n",
    "d=pd.DataFrame(  \n",
    "    d\n",
    ",columns=SCALER_COL)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================== predict ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG['transform'] : True\n"
     ]
    }
   ],
   "source": [
    "PartitionDate = [ d[:-3] for d in  os.listdir(H5_PATH)]\n",
    "random.shuffle(PartitionDate)\n",
    "for partdate in PartitionDate[:1] :\n",
    "    DATA = []\n",
    "    with h5py.File(H5_PATH+partdate+\".h5\", 'r') as f:\n",
    "        DATA = f[partdate][:]\n",
    "    data_shape = DATA.shape\n",
    "    print(f\"CONFIG['transform'] : {CONFIG['transform']}\")\n",
    "    if CONFIG['transform'] or True :\n",
    "        DATA = Scaler.transform(DATA.reshape(-1,data_shape[-1]))\n",
    "        DATA = DATA.reshape(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_x = [SCALER_COL[i] for i in select_x]\n",
    "col_y = [SCALER_COL[i] for i in select_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DATA[:, :, select_x][:]\n",
    "Y_real = DATA[:, :, select_y][:]\n",
    "#===========\n",
    "# X = x_train\n",
    "# Y_real = y_train\n",
    "# #===========\n",
    "dfX = pd.DataFrame(\n",
    "    X[:1].reshape(16, len(select_x)), \n",
    "    columns=col_x)\n",
    "#print(dfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "genVal = model.generator(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = pd.DataFrame(\n",
    "    genVal.numpy()[:1].reshape(16, len(select_y)), \n",
    "    columns=col_y)\n",
    "#print(dfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMDF = pd.concat([dfX, dfY],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF = pd.DataFrame([])\n",
    "rm_col = []\n",
    "for i in SCALER_COL:\n",
    "    if i in SUMDF.columns:\n",
    "         resultDF[i] = SUMDF[i]\n",
    "    else:\n",
    "        rm_col += [i]\n",
    "        resultDF[i] = [1e-8]*16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['transform'] :\n",
    "    decode_transformed=Scaler.inverse_transform(\n",
    "        resultDF\n",
    "    )\n",
    "    decode_transformed=pd.DataFrame(  \n",
    "        decode_transformed\n",
    "    ,columns=SCALER_COL).drop(columns=rm_col)\n",
    "    decode_transformed.loc[decode_transformed['DTE'] < 1e-8] = 0\n",
    "    decode_transformed[col_y] = decode_transformed[col_y].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTRINSIC_VALUE</th>\n",
       "      <th>DTE</th>\n",
       "      <th>C_VEGA</th>\n",
       "      <th>P_VEGA</th>\n",
       "      <th>C_BID</th>\n",
       "      <th>C_ASK</th>\n",
       "      <th>P_BID</th>\n",
       "      <th>P_ASK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.04732</td>\n",
       "      <td>4.749000e-02</td>\n",
       "      <td>9.26</td>\n",
       "      <td>8.80</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.04345</td>\n",
       "      <td>4.407000e-02</td>\n",
       "      <td>8.97</td>\n",
       "      <td>8.30</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.03796</td>\n",
       "      <td>3.899000e-02</td>\n",
       "      <td>9.64</td>\n",
       "      <td>8.31</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.03282</td>\n",
       "      <td>3.237000e-02</td>\n",
       "      <td>9.56</td>\n",
       "      <td>8.97</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.02610</td>\n",
       "      <td>2.809000e-02</td>\n",
       "      <td>8.88</td>\n",
       "      <td>8.54</td>\n",
       "      <td>5.44</td>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.01948</td>\n",
       "      <td>2.434000e-02</td>\n",
       "      <td>8.91</td>\n",
       "      <td>9.06</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.01410</td>\n",
       "      <td>1.613000e-02</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00999</td>\n",
       "      <td>1.311000e-02</td>\n",
       "      <td>9.03</td>\n",
       "      <td>9.44</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>1.590000e-02</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.93</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00493</td>\n",
       "      <td>1.278000e-02</td>\n",
       "      <td>8.32</td>\n",
       "      <td>8.26</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>1.232000e-02</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.62</td>\n",
       "      <td>6.38</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00265</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.44</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00227</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.63</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-7.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00183</td>\n",
       "      <td>1.427000e-02</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.19</td>\n",
       "      <td>5.12</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>1.264000e-02</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.57</td>\n",
       "      <td>5.37</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-8.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00148</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.70</td>\n",
       "      <td>6.27</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    INTRINSIC_VALUE  DTE   C_VEGA        P_VEGA  C_BID  C_ASK  P_BID  P_ASK\n",
       "0              -1.0  4.0  0.04732  4.749000e-02   9.26   8.80   3.64   3.28\n",
       "1              -1.5  4.0  0.04345  4.407000e-02   8.97   8.30   3.74   3.54\n",
       "2              -2.0  4.0  0.03796  3.899000e-02   9.64   8.31   4.09   3.68\n",
       "3              -2.5  4.0  0.03282  3.237000e-02   9.56   8.97   4.68   4.17\n",
       "4              -3.0  4.0  0.02610  2.809000e-02   8.88   8.54   5.44   5.38\n",
       "5              -3.5  4.0  0.01948  2.434000e-02   8.91   9.06   5.83   5.61\n",
       "6              -4.0  4.0  0.01410  1.613000e-02   9.79   9.33   6.11   5.32\n",
       "7              -4.5  4.0  0.00999  1.311000e-02   9.03   9.44   5.82   5.41\n",
       "8              -5.0  4.0  0.00590  1.590000e-02   9.11   8.93   6.02   5.85\n",
       "9              -5.5  4.0  0.00493  1.278000e-02   8.32   8.26   6.14   6.29\n",
       "10             -6.0  4.0  0.00204  1.232000e-02   7.24   7.62   6.38   6.42\n",
       "11             -6.5  4.0  0.00265  1.000000e-08   6.67   6.95   6.44   6.27\n",
       "12             -7.0  4.0  0.00227  1.000000e-08   5.50   5.63   5.33   5.20\n",
       "13             -7.5  4.0  0.00183  1.427000e-02   4.32   4.19   5.12   4.77\n",
       "14             -8.0  4.0  0.00206  1.264000e-02   3.13   3.57   5.37   6.08\n",
       "15             -8.5  4.0  0.00148  1.000000e-08   3.54   3.70   6.27   8.97"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2694477771.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[44], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ======================= real data ==============================\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "======================= real data =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['transform'] :\n",
    "    realdecode_transformed=Scaler.inverse_transform(\n",
    "        DATA[0]\n",
    "    )\n",
    "    realdecode_transformed=pd.DataFrame(  \n",
    "        realdecode_transformed\n",
    "    ,columns=SCALER_COL).drop(columns=rm_col)\n",
    "    realdecode_transformed.loc[realdecode_transformed['DTE'] <= 1e-8] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTRINSIC_VALUE</th>\n",
       "      <th>DTE</th>\n",
       "      <th>C_VEGA</th>\n",
       "      <th>P_VEGA</th>\n",
       "      <th>C_BID</th>\n",
       "      <th>C_ASK</th>\n",
       "      <th>P_BID</th>\n",
       "      <th>P_ASK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.04732</td>\n",
       "      <td>4.749000e-02</td>\n",
       "      <td>6.700000e-01</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.04345</td>\n",
       "      <td>4.407000e-02</td>\n",
       "      <td>4.900000e-01</td>\n",
       "      <td>5.200000e-01</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.03796</td>\n",
       "      <td>3.899000e-02</td>\n",
       "      <td>3.400000e-01</td>\n",
       "      <td>3.500000e-01</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.03282</td>\n",
       "      <td>3.237000e-02</td>\n",
       "      <td>2.300000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.02610</td>\n",
       "      <td>2.809000e-02</td>\n",
       "      <td>1.400000e-01</td>\n",
       "      <td>1.500000e-01</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.01948</td>\n",
       "      <td>2.434000e-02</td>\n",
       "      <td>9.000000e-02</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.01410</td>\n",
       "      <td>1.613000e-02</td>\n",
       "      <td>6.000000e-02</td>\n",
       "      <td>6.000000e-02</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00999</td>\n",
       "      <td>1.311000e-02</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>1.590000e-02</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00493</td>\n",
       "      <td>1.278000e-02</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>1.232000e-02</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>5.87</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00265</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00227</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>6.86</td>\n",
       "      <td>6.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-7.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00183</td>\n",
       "      <td>1.427000e-02</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>1.264000e-02</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>7.87</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-8.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00148</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>9.999994e-09</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>8.37</td>\n",
       "      <td>8.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    INTRINSIC_VALUE  DTE   C_VEGA        P_VEGA         C_BID         C_ASK  \\\n",
       "0              -1.0  4.0  0.04732  4.749000e-02  6.700000e-01  7.000000e-01   \n",
       "1              -1.5  4.0  0.04345  4.407000e-02  4.900000e-01  5.200000e-01   \n",
       "2              -2.0  4.0  0.03796  3.899000e-02  3.400000e-01  3.500000e-01   \n",
       "3              -2.5  4.0  0.03282  3.237000e-02  2.300000e-01  2.500000e-01   \n",
       "4              -3.0  4.0  0.02610  2.809000e-02  1.400000e-01  1.500000e-01   \n",
       "5              -3.5  4.0  0.01948  2.434000e-02  9.000000e-02  1.000000e-01   \n",
       "6              -4.0  4.0  0.01410  1.613000e-02  6.000000e-02  6.000000e-02   \n",
       "7              -4.5  4.0  0.00999  1.311000e-02  3.000000e-02  5.000000e-02   \n",
       "8              -5.0  4.0  0.00590  1.590000e-02  2.000000e-02  2.000000e-02   \n",
       "9              -5.5  4.0  0.00493  1.278000e-02  9.999994e-09  2.000000e-02   \n",
       "10             -6.0  4.0  0.00204  1.232000e-02  9.999994e-09  1.000000e-02   \n",
       "11             -6.5  4.0  0.00265  1.000000e-08  9.999994e-09  9.999994e-09   \n",
       "12             -7.0  4.0  0.00227  1.000000e-08  9.999994e-09  1.000000e-02   \n",
       "13             -7.5  4.0  0.00183  1.427000e-02  9.999994e-09  1.000000e-02   \n",
       "14             -8.0  4.0  0.00206  1.264000e-02  9.999994e-09  9.999994e-09   \n",
       "15             -8.5  4.0  0.00148  1.000000e-08  9.999994e-09  1.000000e-02   \n",
       "\n",
       "    P_BID  P_ASK  \n",
       "0    1.61   1.67  \n",
       "1    1.90   1.96  \n",
       "2    2.28   2.35  \n",
       "3    2.62   2.69  \n",
       "4    3.06   3.16  \n",
       "5    3.52   3.60  \n",
       "6    3.91   4.04  \n",
       "7    4.39   4.50  \n",
       "8    4.94   5.03  \n",
       "9    5.39   5.48  \n",
       "10   5.87   5.98  \n",
       "11   6.36   6.47  \n",
       "12   6.86   6.97  \n",
       "13   7.41   7.52  \n",
       "14   7.87   7.99  \n",
       "15   8.37   8.46  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realdecode_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999994e-09"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9.999994e-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================= _compute_loss =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated_data = [c_bid, c_ask, c_volume, p_bid, p_ask, p_volume]\n",
    "colList = [\"c_bid\", \"c_ask\", \"c_volume\", \"p_bid\", \"p_ask\", \"p_volume\"]\n",
    "generated_data = decode_data[3:]\n",
    "z_mean    = z_mean\n",
    "z_log_var = log_var\n",
    "Y_real    = DATA[:, :, 3:][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  col,genData in zip(colList,generated_data):\n",
    "    print( colList.index(col),col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtract_genData = genData - tf.cast(tf.expand_dims(Y_real[:, :, colList.index(col)], axis=-1)\n",
    "        , tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_values_total = []\n",
    "reconstruction_values_total.append( tf.reduce_mean( tf.square(subtract_genData)   ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_var = tf.clip_by_value(log_var, -1.0, 1.0)\n",
    "kl_loss = -0.5 * tf.reduce_sum(1 + log_var - tf.square(z_mean) - tf.exp(log_var), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(reconstruction_values_total + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "========== kiras vae origi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_real[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " tf.concat(decode_data, axis=-1).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_real[0] -  tf.concat(decode_data, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_loss = tf.reduce_mean(\n",
    "    tf.reduce_sum(\n",
    "        tf.keras.losses.mean_squared_error(Y_real, tf.concat(decode_data, axis=-1)),\n",
    "        axis=(1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_loss = tf.reduce_mean(\n",
    "#     tf.reduce_sum(\n",
    "#         keras.losses.categorical_crossentropy(features_real, features_gen),\n",
    "#         axis=(1),\n",
    "#     )\n",
    "# )\n",
    "# kl_loss = -0.5 * tf.reduce_sum(\n",
    "#     1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), 1\n",
    "# )\n",
    "# kl_loss = tf.reduce_mean(kl_loss)\n",
    "\n",
    "# property_loss = tf.reduce_mean(\n",
    "#     keras.losses.binary_crossentropy(qed_true, qed_pred)\n",
    "# )\n",
    "\n",
    "# graph_loss = self._gradient_penalty(graph_real, graph_generated)\n",
    "\n",
    "# return kl_loss + property_loss + graph_loss + adjacency_loss + features_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "======================= inverse_transform ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 0\n",
    "decode_data = [tf.zeros([1, 32, 1])]*3 + decode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_decode = Scaler.inverse_transform(\n",
    "    np.array([d.numpy().reshape(-1) for d in decode_data]).transpose()\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    invert_decode[:,3:], \n",
    "    columns=SCALER_COL[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f77a7efb8cf15d18a0cd6bbc71a8985efbc57e2467f435a53ada42728ce0a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
