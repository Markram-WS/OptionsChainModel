{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be options chain day1 - end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH     = './data/OptionsEOD.csv/'\n",
    "PARQUET_PATH = './data/OptionsEOD.parquet'\n",
    "PARQUET_STG_PATH = './data/OptionsEOD_STG.parquet'\n",
    "SCALER_COL  = ['DTE','INTRINSIC_VALUE','TOTAL_C_VOLUME', 'TOTAL_P_VOLUME',\t'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK',\t'P_VOLUME' ]\n",
    "SCALER_PATH = './data/scaler.gz'\n",
    " \n",
    "UNIQUE_KEYS = ['QUOTE_DATE','SYMBOL','EXPIRE_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "EOD_CSV = pd.read_csv(CSV_PATH+\"qqq/qqq_eod_201201.txt\", engine='pyarrow')\n",
    "EOD_CSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOD_CSV.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part I\n",
    "#TransformData : \n",
    "#-each partition from EXPIRE_DATE \n",
    "#-csv too parquet\n",
    "#-col. rename \n",
    "def TransformDataI():\n",
    "    scaler = MinMaxScaler()\n",
    "    schema = None\n",
    "    pqwriter = None\n",
    "    for d in os.listdir(CSV_PATH):\n",
    "        for f in os.listdir(CSV_PATH+f\"{d}/\"):\n",
    "            if f.endswith(\".txt\"):\n",
    "                ## load\n",
    "                print( f\"[LOAD] : {CSV_PATH}{d}/{f}        \",end='\\r')\n",
    "                EOD_CSV = pd.read_csv(CSV_PATH+f\"{d}/\"+f, engine='pyarrow')\n",
    "                    \n",
    "                ## rename col.\n",
    "                for c in EOD_CSV.columns:\n",
    "                    EOD_CSV = EOD_CSV.rename( columns={ c:c.strip().replace(']','').replace('[','') } )\n",
    "                \n",
    "                ## add symbol \n",
    "                EOD_CSV['SYMBOL'] = d.upper()\n",
    "                ## add INTRINSIC_VALUE\n",
    "                EOD_CSV['INTRINSIC_VALUE'] = EOD_CSV['UNDERLYING_LAST'] - EOD_CSV['STRIKE']\n",
    "                \n",
    "                ## fillnafillna\n",
    "                EOD_CSV['P_VOLUME'] = EOD_CSV['P_VOLUME'].fillna(0)\n",
    "                EOD_CSV['C_VOLUME'] = EOD_CSV['C_VOLUME'].fillna(0)\n",
    "\n",
    "\n",
    "                \n",
    "                # date columns convert to datetime\n",
    "                for c in [\"QUOTE_READTIME\",\"QUOTE_DATE\",\"EXPIRE_DATE\"]:\n",
    "                    EOD_CSV[c] = pd.to_datetime(EOD_CSV[c])\n",
    "                \n",
    "                #clean float data\n",
    "                for c in ['INTRINSIC_VALUE','C_DELTA','C_GAMMA','C_VEGA','C_THETA','C_RHO','C_IV','C_VOLUME','C_LAST','C_BID','C_ASK','STRIKE','P_BID','P_ASK','P_LAST','P_DELTA','P_GAMMA','P_VEGA','P_THETA','P_RHO','P_IV','P_VOLUME','STRIKE_DISTANCE','STRIKE_DISTANCE_PCT']:\n",
    "                    if EOD_CSV[c].dtype not in ( 'float32','float64'):\n",
    "                        EOD_CSV[c] = EOD_CSV[c].apply(lambda x: x.strip())\n",
    "                        EOD_CSV[c] = EOD_CSV[c].replace('', np.nan).fillna(np.nan)\n",
    "                        EOD_CSV[c] = EOD_CSV[c].astype('float64')\n",
    "                    if EOD_CSV[c].dtype == 'float32':\n",
    "                        EOD_CSV[c] = EOD_CSV[c].astype('float64')\n",
    "                        \n",
    "                # REMAIN_DAYS(int) =>  use DTE col.\n",
    "                #partition with QUOTE_DATE\n",
    "                EOD_CSV['PartitionDate'] = EOD_CSV['QUOTE_DATE'].dt.strftime('%Y-%m')\n",
    "                EOD_CSV.sort_values(['QUOTE_DATE','EXPIRE_DATE','SYMBOL','STRIKE'],ascending =False ) \n",
    "\n",
    "                #scaler(Normalization_\n",
    "                #scaler.partial_fit(EOD_CSV[SCALER_COL])\n",
    "\n",
    "                # save\n",
    "                if os.path.exists(PARQUET_PATH):\n",
    "                  EOD_CSV.to_parquet(PARQUET_PATH, engine='fastparquet', append=True, partition_cols=['PartitionDate'], index=False )\n",
    "                else:\n",
    "                  EOD_CSV.to_parquet(PARQUET_PATH, engine='fastparquet' , partition_cols=['PartitionDate'], index=False  )\n",
    "                    \n",
    "    # joblib.dump(scaler, SCALER_PATH )\n",
    "    # if pqwriter:\n",
    "    #     pqwriter.close()\n",
    "    # print( f\"[DONE]                                                       \",end='\\r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-RunCleanData\n",
    "#TransformDataI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part II \n",
    "#TransformData : \n",
    "# - read each partitions \n",
    "# - Normalization if not have scaler.gz file\n",
    "def strikeZero(df,v,num_rm):\n",
    "    # First, filter based on QUOTE_DATE, SYMBOL, and EXPIRE_DATE\n",
    "    filtered_arr = df[(df['QUOTE_DATE'] == v['QUOTE_DATE']) &\n",
    "                     (df['SYMBOL'] == v['SYMBOL']) &\n",
    "                     (df['EXPIRE_DATE'] == v['EXPIRE_DATE'])]['STRIKE'].values\n",
    "    \n",
    "    # print(max_intrinsic_value)\n",
    "    # print(min_intrinsic_value)\n",
    "    df.loc[ (df['QUOTE_DATE'] == v['QUOTE_DATE']) \n",
    "            & (df['SYMBOL'] == v['SYMBOL']) \n",
    "            & (df['EXPIRE_DATE'] == v['EXPIRE_DATE'])\n",
    "            & (  (df['STRIKE'].isin(filtered_arr[:5].values)  )\n",
    "               | (df['STRIKE'].isin(filtered_arr[-5:].values)   )\n",
    "              ) \n",
    "        , ['DTE', 'INTRINSIC_VALUE', 'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK',\t'P_VOLUME']       \n",
    "    ] = 0\n",
    "    \n",
    "\n",
    "def TransformDataII():\n",
    "    \n",
    "    keys = None#df[unique_keys].sort_values(by=unique_keys).drop_duplicates()\n",
    "    max_option_len = 20\n",
    "    scaler = MinMaxScaler()\n",
    "    PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_PATH) if 'PartitionDate' in d]\n",
    "    options_qoute = {}\n",
    "    for i,partdate in enumerate(PartitionDate) :  \n",
    "        df = pd.read_parquet(PARQUET_PATH,engine='pyarrow'\n",
    "                                     , filters=[('PartitionDate', '=', partdate)]\n",
    "                                    )\n",
    "        #add col options_id\n",
    "        df['OPTIONS_ID'] = None\n",
    "        ####################################################\n",
    "        keys = df[UNIQUE_KEYS].sort_values(by=UNIQUE_KEYS).drop_duplicates()\n",
    "        #loop each keys\n",
    "        for j,v in keys.iterrows():\n",
    "            \n",
    "            df_filter=df[ (df['QUOTE_DATE'] == v['QUOTE_DATE']) & (df['SYMBOL'] == v['SYMBOL']) & (df['EXPIRE_DATE'] == v['EXPIRE_DATE']) ]\n",
    "            qoute = \"\".join(v[ ['SYMBOL','EXPIRE_DATE'] ].apply(str).values)\n",
    "            #add qoute\n",
    "            if qoute not in [*options_qoute.keys()]:\n",
    "                options_qoute[qoute] = {}\n",
    "                options_qoute[qoute]['start_price'] = df_filter['UNDERLYING_LAST'].values[0]\n",
    "                options_qoute[qoute]['strike'] = df_filter[ df_filter['INTRINSIC_VALUE'].abs().isin(df_filter['INTRINSIC_VALUE'].abs().sort_values()[:max_option_len]) ]['STRIKE'].values\n",
    "                options_qoute[qoute]['exp'] = df_filter['EXPIRE_DATE'].values[0]\n",
    "                #check diff UNDERLYING_LAST\n",
    "                if df_filter['UNDERLYING_LAST'].values[0] != round(np.average(df_filter['UNDERLYING_LAST']),4):\n",
    "                    print('[ERROR] : set UNDERLYING_LAST ',qoute )\n",
    "            #rm index max : max_option_len\n",
    "            rm_strike_index = df_filter[ ~df_filter['STRIKE'].isin(options_qoute[qoute]['strike']) ].index\n",
    "            df = df.drop(rm_strike_index)\n",
    "            df_filter = df_filter.drop(rm_strike_index)\n",
    "\n",
    "            # Generate zero strike \n",
    "            # Generate a random float between 0.01 and 1\n",
    "            random_number = random.uniform(0, 1)\n",
    "            nom_rm_rows = [r  for r in [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4] if random_number < r]\n",
    "            strikeZero(df,v,len(nom_rm_rows) )\n",
    "            #TOTAL_P_VOLUME,TOTAL_C_VOLUME,OPTIONS_ID\n",
    "            df.loc[ (df['QUOTE_DATE'] == v['QUOTE_DATE']) \n",
    "            & (df['SYMBOL'] == v['SYMBOL']) \n",
    "            & (df['EXPIRE_DATE'] == v['EXPIRE_DATE']) \n",
    "            , ['TOTAL_P_VOLUME','TOTAL_C_VOLUME','OPTIONS_ID']\n",
    "            ] = [\n",
    "                df_filter['P_VOLUME'].sum(),\n",
    "                df_filter['C_VOLUME'].sum(),\n",
    "                pd.util.hash_pandas_object(pd.Series([i,j])).sum()\n",
    "            ]\n",
    "            \n",
    "        #clear expire options_qoute\n",
    "        for qi in list(options_qoute.keys()):\n",
    "            if options_qoute[qi]['exp'] < df['QUOTE_DATE'].values[0]:\n",
    "                options_qoute.pop(qi)\n",
    "    \n",
    "        ###################################################\n",
    "\n",
    "        # scaler.partial_fit\n",
    "        scaler.partial_fit(df[SCALER_COL])\n",
    "        print(f\"[Processing] {round(((i+1)/len(PartitionDate))*100,2)}%   \",end='\\r')\n",
    "        \n",
    "        # save\n",
    "        if os.path.exists(PARQUET_STG_PATH):\n",
    "          df.to_parquet(PARQUET_STG_PATH, engine='fastparquet', append=True, partition_cols=['PartitionDate'], index=False )\n",
    "        else:\n",
    "          df.to_parquet(PARQUET_STG_PATH, engine='fastparquet' , partition_cols=['PartitionDate'], index=False  )\n",
    "            \n",
    "    joblib.dump(scaler, SCALER_PATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformDataII()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example data\n",
    "PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_STG_PATH) if 'PartitionDate' in d]\n",
    "options_qoute = {}\n",
    "for i,partdate in enumerate(PartitionDate[5:6]) :  \n",
    "    df = pd.read_parquet(PARQUET_PATH,engine='pyarrow'\n",
    "                                 , filters=[('PartitionDate', '=', partdate)]\n",
    "                                )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUOTE_UNIXTIME</th>\n",
       "      <th>QUOTE_READTIME</th>\n",
       "      <th>QUOTE_DATE</th>\n",
       "      <th>QUOTE_TIME_HOURS</th>\n",
       "      <th>UNDERLYING_LAST</th>\n",
       "      <th>EXPIRE_DATE</th>\n",
       "      <th>EXPIRE_UNIX</th>\n",
       "      <th>DTE</th>\n",
       "      <th>C_DELTA</th>\n",
       "      <th>C_GAMMA</th>\n",
       "      <th>...</th>\n",
       "      <th>P_VEGA</th>\n",
       "      <th>P_THETA</th>\n",
       "      <th>P_RHO</th>\n",
       "      <th>P_IV</th>\n",
       "      <th>P_VOLUME</th>\n",
       "      <th>STRIKE_DISTANCE</th>\n",
       "      <th>STRIKE_DISTANCE_PCT</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>INTRINSIC_VALUE</th>\n",
       "      <th>PartitionDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1338580800</td>\n",
       "      <td>2012-06-01 16:00:00</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.17</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>1338580800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93111</td>\n",
       "      <td>0.01477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>-0.00465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.74919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.103</td>\n",
       "      <td>SPY</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338580800</td>\n",
       "      <td>2012-06-01 16:00:00</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.17</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>1338580800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92158</td>\n",
       "      <td>0.01731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>-0.00519</td>\n",
       "      <td>-0.00022</td>\n",
       "      <td>0.69439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.095</td>\n",
       "      <td>SPY</td>\n",
       "      <td>12.17</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1338580800</td>\n",
       "      <td>2012-06-01 16:00:00</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.17</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>1338580800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91846</td>\n",
       "      <td>0.01973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>-0.00507</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>0.63877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.087</td>\n",
       "      <td>SPY</td>\n",
       "      <td>11.17</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338580800</td>\n",
       "      <td>2012-06-01 16:00:00</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.17</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>1338580800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95615</td>\n",
       "      <td>0.01983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>-0.00515</td>\n",
       "      <td>-0.00044</td>\n",
       "      <td>0.58294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.079</td>\n",
       "      <td>SPY</td>\n",
       "      <td>10.17</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1338580800</td>\n",
       "      <td>2012-06-01 16:00:00</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.17</td>\n",
       "      <td>2012-06-01</td>\n",
       "      <td>1338580800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95448</td>\n",
       "      <td>0.02382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>-0.00516</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.52753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.072</td>\n",
       "      <td>SPY</td>\n",
       "      <td>9.17</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68728</th>\n",
       "      <td>1341000000</td>\n",
       "      <td>2012-06-29 16:00:00</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.14</td>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>1419022800</td>\n",
       "      <td>903.04</td>\n",
       "      <td>0.40045</td>\n",
       "      <td>0.02129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37628</td>\n",
       "      <td>-0.00434</td>\n",
       "      <td>-0.70972</td>\n",
       "      <td>0.32386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.169</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>-10.86</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68729</th>\n",
       "      <td>1341000000</td>\n",
       "      <td>2012-06-29 16:00:00</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.14</td>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>1419022800</td>\n",
       "      <td>903.04</td>\n",
       "      <td>0.30755</td>\n",
       "      <td>0.02010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36639</td>\n",
       "      <td>-0.00465</td>\n",
       "      <td>-0.73891</td>\n",
       "      <td>0.33269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.247</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>-15.86</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68730</th>\n",
       "      <td>1341000000</td>\n",
       "      <td>2012-06-29 16:00:00</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.14</td>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>1419022800</td>\n",
       "      <td>903.04</td>\n",
       "      <td>0.26723</td>\n",
       "      <td>0.01683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34916</td>\n",
       "      <td>-0.00428</td>\n",
       "      <td>-0.74556</td>\n",
       "      <td>0.33833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.325</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>-20.86</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68731</th>\n",
       "      <td>1341000000</td>\n",
       "      <td>2012-06-29 16:00:00</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.14</td>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>1419022800</td>\n",
       "      <td>903.04</td>\n",
       "      <td>0.17054</td>\n",
       "      <td>0.01484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33047</td>\n",
       "      <td>-0.00343</td>\n",
       "      <td>-0.74398</td>\n",
       "      <td>0.34950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.403</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>-25.86</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68732</th>\n",
       "      <td>1341000000</td>\n",
       "      <td>2012-06-29 16:00:00</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.14</td>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>1419022800</td>\n",
       "      <td>903.04</td>\n",
       "      <td>0.14035</td>\n",
       "      <td>0.01237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30933</td>\n",
       "      <td>-0.00316</td>\n",
       "      <td>-0.72735</td>\n",
       "      <td>0.36070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.481</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>-30.86</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68733 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QUOTE_UNIXTIME      QUOTE_READTIME QUOTE_DATE  QUOTE_TIME_HOURS  \\\n",
       "0          1338580800 2012-06-01 16:00:00 2012-06-01              16.0   \n",
       "1          1338580800 2012-06-01 16:00:00 2012-06-01              16.0   \n",
       "2          1338580800 2012-06-01 16:00:00 2012-06-01              16.0   \n",
       "3          1338580800 2012-06-01 16:00:00 2012-06-01              16.0   \n",
       "4          1338580800 2012-06-01 16:00:00 2012-06-01              16.0   \n",
       "...               ...                 ...        ...               ...   \n",
       "68728      1341000000 2012-06-29 16:00:00 2012-06-29              16.0   \n",
       "68729      1341000000 2012-06-29 16:00:00 2012-06-29              16.0   \n",
       "68730      1341000000 2012-06-29 16:00:00 2012-06-29              16.0   \n",
       "68731      1341000000 2012-06-29 16:00:00 2012-06-29              16.0   \n",
       "68732      1341000000 2012-06-29 16:00:00 2012-06-29              16.0   \n",
       "\n",
       "       UNDERLYING_LAST EXPIRE_DATE  EXPIRE_UNIX     DTE  C_DELTA  C_GAMMA  \\\n",
       "0               128.17  2012-06-01   1338580800    0.00  0.93111  0.01477   \n",
       "1               128.17  2012-06-01   1338580800    0.00  0.92158  0.01731   \n",
       "2               128.17  2012-06-01   1338580800    0.00  0.91846  0.01973   \n",
       "3               128.17  2012-06-01   1338580800    0.00  0.95615  0.01983   \n",
       "4               128.17  2012-06-01   1338580800    0.00  0.95448  0.02382   \n",
       "...                ...         ...          ...     ...      ...      ...   \n",
       "68728            64.14  2014-12-19   1419022800  903.04  0.40045  0.02129   \n",
       "68729            64.14  2014-12-19   1419022800  903.04  0.30755  0.02010   \n",
       "68730            64.14  2014-12-19   1419022800  903.04  0.26723  0.01683   \n",
       "68731            64.14  2014-12-19   1419022800  903.04  0.17054  0.01484   \n",
       "68732            64.14  2014-12-19   1419022800  903.04  0.14035  0.01237   \n",
       "\n",
       "       ...   P_VEGA  P_THETA    P_RHO     P_IV  P_VOLUME  STRIKE_DISTANCE  \\\n",
       "0      ...  0.00061 -0.00465  0.00000  0.74919       0.0             13.2   \n",
       "1      ...  0.00086 -0.00519 -0.00022  0.69439       0.0             12.2   \n",
       "2      ...  0.00028 -0.00507 -0.00007  0.63877       0.0             11.2   \n",
       "3      ...  0.00111 -0.00515 -0.00044  0.58294       0.0             10.2   \n",
       "4      ...  0.00103 -0.00516  0.00000  0.52753       0.0              9.2   \n",
       "...    ...      ...      ...      ...      ...       ...              ...   \n",
       "68728  ...  0.37628 -0.00434 -0.70972  0.32386       NaN             10.9   \n",
       "68729  ...  0.36639 -0.00465 -0.73891  0.33269       0.0             15.9   \n",
       "68730  ...  0.34916 -0.00428 -0.74556  0.33833       NaN             20.9   \n",
       "68731  ...  0.33047 -0.00343 -0.74398  0.34950       NaN             25.9   \n",
       "68732  ...  0.30933 -0.00316 -0.72735  0.36070       NaN             30.9   \n",
       "\n",
       "      STRIKE_DISTANCE_PCT  SYMBOL  INTRINSIC_VALUE  PartitionDate  \n",
       "0                   0.103     SPY            13.17        2012-06  \n",
       "1                   0.095     SPY            12.17        2012-06  \n",
       "2                   0.087     SPY            11.17        2012-06  \n",
       "3                   0.079     SPY            10.17        2012-06  \n",
       "4                   0.072     SPY             9.17        2012-06  \n",
       "...                   ...     ...              ...            ...  \n",
       "68728               0.169     QQQ           -10.86        2012-06  \n",
       "68729               0.247     QQQ           -15.86        2012-06  \n",
       "68730               0.325     QQQ           -20.86        2012-06  \n",
       "68731               0.403     QQQ           -25.86        2012-06  \n",
       "68732               0.481     QQQ           -30.86        2012-06  \n",
       "\n",
       "[68733 rows x 36 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[UNIQUE_KEYS]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39mUNIQUE_KEYS)\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#loop each keys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j,v \u001b[38;5;129;01min\u001b[39;00m keys\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "keys = df[UNIQUE_KEYS].sort_values(by=UNIQUE_KEYS).drop_duplicates()\n",
    "#loop each keys\n",
    "for j,v in keys.iterrows():\n",
    "\n",
    "    df_filter=df[ (df['QUOTE_DATE'] == v['QUOTE_DATE']) \n",
    "        & (df['SYMBOL'] == v['SYMBOL']) \n",
    "        & (df['EXPIRE_DATE'] == v['EXPIRE_DATE']) \n",
    "    ]\n",
    "\n",
    "    df_filter=df_filter[\n",
    "        (df_filter['INTRINSIC_VALUE'].max() == df_filter['INTRINSIC_VALUE'])\n",
    "    |   (df_filter['INTRINSIC_VALUE'].min() == df_filter['INTRINSIC_VALUE'])\n",
    "    ]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3============== sampling show 3==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartitionDate = [ d[-7:] for d in  os.listdir(PARQUET_STG_PATH) if 'PartitionDate' in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import clear_output,display, HTML\n",
    "\n",
    "for i in range(10):\n",
    "    ran_partiion=random.choice(PartitionDate)\n",
    "\n",
    "    df = pd.read_parquet(PARQUET_STG_PATH,engine='pyarrow'\n",
    "                                 , filters=[('PartitionDate', '=', ran_partiion)]\n",
    "                                )\n",
    "    key = random.choice( [*df[UNIQUE_KEYS].sort_values(by=UNIQUE_KEYS).drop_duplicates().values] )\n",
    "\n",
    "    df_filtered=df[ (df['QUOTE_DATE'] == key[0]) \n",
    "        & (df['SYMBOL'] == key[1]) \n",
    "        & (df['EXPIRE_DATE'] == key[2]) \n",
    "    ]\n",
    "    break\n",
    "    display(HTML(df_filter[['STRIKE']+SCALER_COL].to_html()))\n",
    "    input('Next ...')\n",
    "    clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.63, 81.63, 82.63, 83.63, 84.63, 85.63, 86.63, 87.63, 88.63,\n",
       "       89.63, 90.63, 91.63, 92.63, 93.63, 94.63, 95.63, 96.63, 97.63,\n",
       "       98.63, 99.63])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['STRIKE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.63, 81.63, 82.63, 83.63, 84.63])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([95.63, 96.63, 97.63, 98.63, 99.63])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host 10.7.55.66 is reachable.\n",
      "Port 8080 is open.\n"
     ]
    }
   ],
   "source": [
    "    max_value = filtered_df[['STRIKE']].sort_values(by=['STRIKE'], ascending=True)\n",
    "    min_value = filtered_df[['STRIKE']].sort_values(by=['STRIKE'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14543938847800026030"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.util.hash_pandas_object(pd.Series([2,1])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14468241752409847283"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.util.hash_pandas_object(pd.Series([2,0])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7582650688657438907"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.util.hash_pandas_object(pd.Series([0,2])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f77a7efb8cf15d18a0cd6bbc71a8985efbc57e2467f435a53ada42728ce0a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
